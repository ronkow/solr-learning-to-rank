{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SENDING QUERIES TO SOLR TO COMPARE SEARCH RESULTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random    \n",
    "import os        \n",
    "import csv       \n",
    "import json      \n",
    "import requests  \n",
    "import urllib    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATA PATHS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR  = \"data/\"\n",
    "FEATURE_QUERY_VALIDATE_TEST = os.path.join(DATA_DIR, \"feature/feature_query_validate_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GLOBAL VARIABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOLR_URL = \"http://localhost:8983/solr/core1\"\n",
    "\n",
    "N = 10    # Top N results to display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GET A RANDOM QUERY FROM THE VALIDATION_TEST DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_query(myseed):\n",
    "    \"\"\"\n",
    "    Select a random query from the query/validation dataset\n",
    "    Parameter:\n",
    "        myseed: seed value\n",
    "    \"\"\"\n",
    "    with open(FEATURE_QUERY_VALIDATE_TEST) as f:\n",
    "        QUERY_LIST = [ {k: v for k, v in row.items()} for row in csv.DictReader(f, skipinitialspace=True) ]\n",
    "    \n",
    "    random.seed(myseed)\n",
    "    random.shuffle(QUERY_LIST)\n",
    "       \n",
    "    query = QUERY_LIST[0]  \n",
    "    \n",
    "    return query   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HELPER FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_results(docs, query, ans, topic, top_n):\n",
    "\n",
    "    print(f\"Top {top_n} results for the query: {query} (answer: {ans}, topic: {topic})\\n\")\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc_id = int(doc[\"id\"])\n",
    "        qb_question = doc[\"qb_question\"][0]     # solr indexed the data as a list! Can this be changed?\n",
    "        qb_answer = doc[\"qb_answer\"][0]\n",
    "        qb_topic_id = doc[\"qb_topic_id\"][0]\n",
    "        print(f\"doc_id: {doc_id} \\t {qb_question} ({qb_answer})(topic: {qb_topic_id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_solr(payload):\n",
    "    \n",
    "    params = urllib.parse.urlencode(payload, quote_via=urllib.parse.quote_plus)\n",
    "    search_url = SOLR_URL + \"/query?\" + params\n",
    "    resp = requests.get(search_url)\n",
    "    resp_json = json.loads(resp.text)\n",
    "    docs = resp_json[\"response\"][\"docs\"]\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **QUERY to SOLR BY DEFAULT BM25 (ENTIRE SENTENCE or SUBSTRING)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODEL: Default Solr (entire sentence)\n",
    "\n",
    "def run_query_default_qa(q):\n",
    "       \n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "    query = q['qa']\n",
    "    \n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"qa\",          # for dismax query parser \n",
    "        #\"df\": \"qa\",         # for standard query parser\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N        \n",
    "        \n",
    "        # OPTIONAL PARAMS\n",
    "        #\"sort\": \"score desc\",\n",
    "        #\"start\": 0,\n",
    "        #\"fq\":\n",
    "        #\"debug\": \"all\",\n",
    "        #\"omitHeader\": \"false\",\n",
    "        #\"explainOther\": \"\",\n",
    "        #\"segmentTerminateEarly\": \"false\",\n",
    "        #\"omitHeader\": \"false\",\n",
    "        #\"echoParams\": \"explicit\",\n",
    "        #\"timeAllowed\": 1000000,\n",
    "        #\"wt\": \"json\",\n",
    "        #\"indent\": \"true\",\n",
    "    }\n",
    "\n",
    "    docs = query_solr(payload)\n",
    "    print(\"QUERY: ENTIRE SENTENCE, ANSWER NOT INDICATED\\n\")\n",
    "    print(\"Default Solr results:\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODEL: Default Solr (substring)\n",
    "\n",
    "def run_query_default_ss(q):\n",
    "       \n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "    query = q['ss']\n",
    "    \n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"ss\",\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N\n",
    "    }\n",
    "\n",
    "    docs = query_solr(payload)\n",
    "    print(\"QUERY: SUBSTRING, ANSWER INDICATED\\n\")\n",
    "    print(\"Default Solr results:\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **QUERY to SOLR USING BASELINE MODELS**\n",
    "#### Baseline models only have one feature: BM25 for entire sentence (Model 1) or BM25 for substring (Model 2)\n",
    "\n",
    "#### When we enable LTR, Solr will rerank the original results from default BM25 (i.e., when no ranking models are used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LTR BASELINE MODEL 1 (entire sentence)\n",
    "\n",
    "def run_query_lambdamart_baseline_model1(q):\n",
    "    \n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "    query = q['qa']\n",
    "\n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"qa\",\n",
    "        \"rq\": f'{{!ltr model=lambdamart_model1_baseline reRankDocs=1002}}',\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N\n",
    "    }\n",
    "\n",
    "    docs = query_solr(payload)\n",
    "    print(\"LTR Baseline Model 1 results:\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LTR BASELINE MODEL 2 (substring)\n",
    "\n",
    "def run_query_lambdamart_baseline_model2(q):\n",
    "    \n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "    query = q['ss']\n",
    "\n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"ss\",\n",
    "        \"rq\": f'{{!ltr model=lambdamart_model2_baseline reRankDocs=1002}}',\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N\n",
    "    }\n",
    "\n",
    "    docs = query_solr(payload)\n",
    "    print(\"LTR Baseline Model 2 results:\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **QUERY to SOLR USING MODELS 1 AND 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LTR MODEL 1\n",
    "\n",
    "def run_query_lambdamart_model1(q):\n",
    "\n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "    query = q['qa']\n",
    "    \n",
    "    f2 = q[\"qa_pos\"]\n",
    "    f3 = q[\"qa_pos_bigram\"]\n",
    "    f4 = q[\"qa_pos_trigram\"]\n",
    "    f5 = q[\"qa_parse_tree\"]\n",
    "    \n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"qa\",\n",
    "        \"rq\": f'{{!ltr model=lambdamart_model1  reRankDocs=1002 \\\n",
    "            efi.q2=\"{f2}\" \\\n",
    "            efi.q3=\"{f3}\" \\\n",
    "            efi.q4=\"{f4}\" \\\n",
    "            efi.q5=\"{f5}\"}}',\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N\n",
    "    }\n",
    "\n",
    "    docs = query_solr(payload)\n",
    "    print(\"LTR Model 1 results:\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LTR MODEL 2\n",
    "\n",
    "def run_query_lambdamart_model2(q):\n",
    "    \n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "    query = q['ss']\n",
    "    \n",
    "    f2 = q[\"ss_pos\"]\n",
    "    f3 = q[\"ss_pos_bigram\"]\n",
    "    f4 = q[\"ss_pos_trigram\"]\n",
    "    f5 = q[\"ss_parse_tree\"]\n",
    "    f6 = q[\"before\"]\n",
    "    f7 = q[\"before_last\"]\n",
    "    f8 = (q[\"before_last_pos\"]).lower()\n",
    "    f9 = q[\"before_pos\"]\n",
    "    f10 = q[\"before_pos_bigram\"]\n",
    "    f11 = q[\"before_pos_trigram\"]\n",
    "    f12 = q[\"before_parse_tree\"]\n",
    "    f13 = q[\"after\"]\n",
    "    f14 = q[\"after_first\"]\n",
    "    f15 = (q[\"after_first_pos\"]).lower()\n",
    "    f16 = q[\"after_pos\"]\n",
    "    f17 = q[\"after_pos_bigram\"]\n",
    "    f18 = q[\"after_pos_trigram\"]\n",
    "    f19 = q[\"after_parse_tree\"]\n",
    "    f20 = q[\"ans\"]\n",
    "    f21 = q[\"ans_first\"]\n",
    "    f22 = q[\"ans_last\"]\n",
    "    f23 = (q[\"ans_pos\"]).lower()\n",
    "    f24 = (q[\"ans_first_pos\"]).lower()\n",
    "    f25 = (q[\"ans_last_pos\"]).lower()\n",
    "    f26 = q[\"ans_is_first\"]\n",
    "    f27 = q[\"ans_is_last\"]\n",
    "    f28 = q[\"ans_length\"]\n",
    "    \n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"ss\",\n",
    "        \"rq\": f'{{!ltr model=lambdamart_model2  reRankDocs=1002 \\\n",
    "            efi.q2=\"{f2}\" \\\n",
    "            efi.q3=\"{f3}\" \\\n",
    "            efi.q4=\"{f4}\" \\\n",
    "            efi.q5=\"{f5}\" \\\n",
    "            efi.q6=\"{f6}\" \\\n",
    "            efi.q7=\"{f7}\" \\\n",
    "            efi.q8=\"{f8}\" \\\n",
    "            efi.q9=\"{f9}\" \\\n",
    "            efi.q10=\"{f10}\" \\\n",
    "            efi.q11=\"{f11}\" \\\n",
    "            efi.q12=\"{f12}\" \\\n",
    "            efi.q13=\"{f13}\" \\\n",
    "            efi.q14=\"{f14}\" \\\n",
    "            efi.q15=\"{f15}\" \\\n",
    "            efi.q16=\"{f16}\" \\\n",
    "            efi.q17=\"{f17}\" \\\n",
    "            efi.q18=\"{f18}\" \\\n",
    "            efi.q19=\"{f19}\" \\\n",
    "            efi.q20=\"{f20}\" \\\n",
    "            efi.q21=\"{f21}\" \\\n",
    "            efi.q22=\"{f22}\" \\\n",
    "            efi.q23=\"{f23}\" \\\n",
    "            efi.q24=\"{f24}\" \\\n",
    "            efi.q25=\"{f25}\" \\\n",
    "            efi.q26=\"{f26}\" \\\n",
    "            efi.q27=\"{f27}\" \\\n",
    "            efi.q28=\"{f28}\"}}',\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N,\n",
    "    }\n",
    "    \n",
    "    docs = query_solr(payload)\n",
    "    print(\"LTR Model 2 results:\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TESTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '9129',\n",
       " 'qb_question': \"I can * myself so you don't have to be concerned.\",\n",
       " 'qb_answer': 'look after',\n",
       " 'qb_topic_id': '3',\n",
       " 'topic': 'phrasal verbs',\n",
       " 'qa': \"I can look after myself so you don't have to be concerned.\",\n",
       " 'qa_pos': 'PRP MD VB IN PRP RB PRP VBP VB TO VB JJ',\n",
       " 'qa_pos_bigram': 'PRP_MD MD_VB VB_IN IN_PRP PRP_RB RB_PRP PRP_VBP VBP_VB VB_TO TO_VB VB_JJ',\n",
       " 'qa_pos_trigram': 'PRP_MD_VB MD_VB_IN VB_IN_PRP IN_PRP_RB PRP_RB_PRP RB_PRP_VBP PRP_VBP_VB VBP_VB_TO VB_TO_VB TO_VB_JJ',\n",
       " 'qa_parse_tree': 'S_NP_VP_. NP_PRP VP_MD_VP VP_VB_PP_SBAR PP_IN_NP NP_PRP SBAR_IN_S S_NP_VP NP_PRP VP_VBP_RB_VP VP_VB_S S_VP VP_TO_VP VP_VB_ADJP ADJP_JJ',\n",
       " 'ss': \"I can look after myself so you don't\",\n",
       " 'ss_pos': 'PRP MD VB IN PRP RB PRP VBP',\n",
       " 'ss_pos_bigram': 'PRP_MD MD_VB VB_IN IN_PRP PRP_RB RB_PRP PRP_VBP',\n",
       " 'ss_pos_trigram': 'PRP_MD_VB MD_VB_IN VB_IN_PRP IN_PRP_RB PRP_RB_PRP RB_PRP_VBP',\n",
       " 'ss_parse_tree': 'S_NP_VP NP_PRP VP_MD_VP VP_VB_PP_SBAR PP_IN_NP NP_PRP SBAR_IN_S S_NP_VP NP_PRP VP_VBP_RB',\n",
       " 'before': 'I can',\n",
       " 'before_last': 'can',\n",
       " 'before_last_pos': 'MD',\n",
       " 'before_pos': 'PRP MD',\n",
       " 'before_pos_bigram': 'PRP_MD',\n",
       " 'before_pos_trigram': '',\n",
       " 'before_parse_tree': 'S_NP_VP NP_PRP VP_MD',\n",
       " 'after': \"myself so you don't\",\n",
       " 'after_first': 'myself',\n",
       " 'after_first_pos': 'PRP',\n",
       " 'after_pos': 'PRP RB PRP VBP',\n",
       " 'after_pos_bigram': 'PRP_RB RB_PRP PRP_VBP',\n",
       " 'after_pos_trigram': 'PRP_RB_PRP RB_PRP_VBP',\n",
       " 'after_parse_tree': 'FRAG_SBAR SBAR_NP_IN_S NP_PRP S_NP_VP NP_PRP VP_VBP_RB',\n",
       " 'ans': 'look after',\n",
       " 'ans_first': 'look',\n",
       " 'ans_last': 'after',\n",
       " 'ans_pos': 'NN_IN',\n",
       " 'ans_first_pos': 'NN',\n",
       " 'ans_last_pos': 'IN',\n",
       " 'ans_is_first': 'y',\n",
       " 'ans_is_last': 'y',\n",
       " 'ans_length': '2.0'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_random_query(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: ENTIRE SENTENCE, ANSWER NOT INDICATED\n",
      "\n",
      "Default Solr results:\n",
      "Top 10 results for the query: I can look after myself so you don't have to be concerned. (answer: look after, topic: 3)\n",
      "\n",
      "doc_id: 979 \t He can * himself so you don't have to worry. (look after)(topic: 3)\n",
      "doc_id: 392 \t She is very independent. She can * herself. (look after)(topic: 3)\n",
      "doc_id: 393 \t I hope you will * my garden when I am gone. (look after)(topic: 3)\n",
      "doc_id: 941 \t Look at those two dogs. I have never seen * so playful before. (them)(topic: 5)\n",
      "doc_id: 826 \t Be careful when you handle the knife. Don't cut *. (yourself)(topic: 5)\n",
      "doc_id: 273 \t I know I should have waited for you * I was so hungry just now. (but)(topic: 2)\n",
      "doc_id: 822 \t I finished the work all by * after three long months. (myself)(topic: 5)\n",
      "doc_id: 233 \t You will not be able to cancel this contract * you have signed it. (once)(topic: 2)\n",
      "doc_id: 60 \t Thank you for your consideration. I look forward to hearing * you. (from)(topic: 1)\n",
      "doc_id: 692 \t This time next month, I * myself in Paris. (will be enjoying)(topic: 4)\n",
      "\n",
      "LTR Baseline Model 1 results:\n",
      "Top 10 results for the query: I can look after myself so you don't have to be concerned. (answer: look after, topic: 3)\n",
      "\n",
      "doc_id: 979 \t He can * himself so you don't have to worry. (look after)(topic: 3)\n",
      "doc_id: 393 \t I hope you will * my garden when I am gone. (look after)(topic: 3)\n",
      "doc_id: 392 \t She is very independent. She can * herself. (look after)(topic: 3)\n",
      "doc_id: 941 \t Look at those two dogs. I have never seen * so playful before. (them)(topic: 5)\n",
      "doc_id: 60 \t Thank you for your consideration. I look forward to hearing * you. (from)(topic: 1)\n",
      "doc_id: 206 \t I need to talk to you * you are done with your work. (after)(topic: 2)\n",
      "doc_id: 259 \t You can come to me * you need help. (whenever)(topic: 2)\n",
      "doc_id: 273 \t I know I should have waited for you * I was so hungry just now. (but)(topic: 2)\n",
      "doc_id: 692 \t This time next month, I * myself in Paris. (will be enjoying)(topic: 4)\n",
      "doc_id: 822 \t I finished the work all by * after three long months. (myself)(topic: 5)\n",
      "\n",
      "LTR Model 1 results:\n",
      "Top 10 results for the query: I can look after myself so you don't have to be concerned. (answer: look after, topic: 3)\n",
      "\n",
      "doc_id: 592 \t I * the kitchen so I am done with housework. (have cleaned)(topic: 4)\n",
      "doc_id: 979 \t He can * himself so you don't have to worry. (look after)(topic: 3)\n",
      "doc_id: 10 \t I will be in Tokyo * two weeks. (for)(topic: 1)\n",
      "doc_id: 183 \t He tends to feel uneasy when he is * strangers. (among)(topic: 1)\n",
      "doc_id: 203 \t He had already left * I could speak to him. (before)(topic: 2)\n",
      "doc_id: 209 \t Soon * we set off, the car began to make strange noises. (after)(topic: 2)\n",
      "doc_id: 202 \t * we make a decision, I would like to give everyone a chance to say something. (Before)(topic: 2)\n",
      "doc_id: 220 \t I started to wonder * we had made the right decision. (whether)(topic: 2)\n",
      "doc_id: 227 \t I will keep on dreaming * my dreams come true. (until)(topic: 2)\n",
      "doc_id: 224 \t You cannot go for the mountain hike * I come along. (unless)(topic: 2)\n",
      "\n",
      "QUERY: SUBSTRING, ANSWER INDICATED\n",
      "\n",
      "Default Solr results:\n",
      "Top 10 results for the query: I can look after myself so you don't (answer: look after, topic: 3)\n",
      "\n",
      "doc_id: 979 \t He can * himself so you don't have to worry. (look after)(topic: 3)\n",
      "doc_id: 392 \t She is very independent. She can * herself. (look after)(topic: 3)\n",
      "doc_id: 393 \t I hope you will * my garden when I am gone. (look after)(topic: 3)\n",
      "doc_id: 744 \t Can you show * where I can find a good supermarket? (me)(topic: 5)\n",
      "doc_id: 414 \t I will * how we can improve the work processes. (look into)(topic: 3)\n",
      "doc_id: 394 \t I * my neighbour's dog when he is away for business. (look after)(topic: 3)\n",
      "doc_id: 210 \t I went home immediately * I met you. (after)(topic: 2)\n",
      "doc_id: 273 \t I know I should have waited for you * I was so hungry just now. (but)(topic: 2)\n",
      "doc_id: 474 \t I am counting on you. Please don't *. (let me down)(topic: 3)\n",
      "doc_id: 718 \t Don't worry, * will not be blamed for this mess your team members created. (you)(topic: 5)\n",
      "\n",
      "LTR Baseline Model 2 results:\n",
      "Top 10 results for the query: I can look after myself so you don't (answer: look after, topic: 3)\n",
      "\n",
      "doc_id: 979 \t He can * himself so you don't have to worry. (look after)(topic: 3)\n",
      "doc_id: 392 \t She is very independent. She can * herself. (look after)(topic: 3)\n",
      "doc_id: 393 \t I hope you will * my garden when I am gone. (look after)(topic: 3)\n",
      "doc_id: 744 \t Can you show * where I can find a good supermarket? (me)(topic: 5)\n",
      "doc_id: 210 \t I went home immediately * I met you. (after)(topic: 2)\n",
      "doc_id: 349 \t You can * if you want but you must watch the proceedings in silence. (come along)(topic: 3)\n",
      "doc_id: 491 \t If you * so easily, you will never succeed. (give up)(topic: 3)\n",
      "doc_id: 273 \t I know I should have waited for you * I was so hungry just now. (but)(topic: 2)\n",
      "doc_id: 474 \t I am counting on you. Please don't *. (let me down)(topic: 3)\n",
      "doc_id: 718 \t Don't worry, * will not be blamed for this mess your team members created. (you)(topic: 5)\n",
      "\n",
      "LTR Model 2 results:\n",
      "Top 10 results for the query: I can look after myself so you don't (answer: look after, topic: 3)\n",
      "\n",
      "doc_id: 979 \t He can * himself so you don't have to worry. (look after)(topic: 3)\n",
      "doc_id: 393 \t I hope you will * my garden when I am gone. (look after)(topic: 3)\n",
      "doc_id: 394 \t I * my neighbour's dog when he is away for business. (look after)(topic: 3)\n",
      "doc_id: 395 \t The nurses * the patients very well in this hospital. (look after)(topic: 3)\n",
      "doc_id: 392 \t She is very independent. She can * herself. (look after)(topic: 3)\n",
      "doc_id: 469 \t I * seeing a dentist for far too long. (put off)(topic: 3)\n",
      "doc_id: 384 \t You will have to * your rifles before the new gun laws take effect. (turn in)(topic: 3)\n",
      "doc_id: 414 \t I will * how we can improve the work processes. (look into)(topic: 3)\n",
      "doc_id: 420 \t I was asked to * the report before sending it for approval. (look over)(topic: 3)\n",
      "doc_id: 417 \t Please * my report quickly and tell me if it is good enough. (look over)(topic: 3)\n"
     ]
    }
   ],
   "source": [
    "query = select_random_query(8)\n",
    "\n",
    "run_query_default_qa(query)\n",
    "print('')\n",
    "run_query_lambdamart_baseline_model1(query)\n",
    "print('')\n",
    "run_query_lambdamart_model1(query)\n",
    "print('')\n",
    "\n",
    "run_query_default_ss(query)\n",
    "print('')\n",
    "run_query_lambdamart_baseline_model2(query)\n",
    "print('')\n",
    "run_query_lambdamart_model2(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

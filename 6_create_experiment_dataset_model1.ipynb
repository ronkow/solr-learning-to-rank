{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATA PATHS, GLOBAL VARIABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR   = \"data/\"\n",
    "\n",
    "# Model 1 datasets\n",
    "FILE_MODEL1_TRAIN    = os.path.join(DATA_DIR, \"final/model1_train.txt\")\n",
    "FILE_MODEL1_VALIDATE = os.path.join(DATA_DIR, \"final/model1_validate.txt\")\n",
    "FILE_MODEL1_TEST     = os.path.join(DATA_DIR, \"final/model1_test.txt\")\n",
    "\n",
    "# BASELINE\n",
    "# Datasets with field: WORDS only\n",
    "FILE_BASE_TRAIN    = os.path.join(DATA_DIR, \"experiment_model1/base_train.txt\")\n",
    "FILE_BASE_VALIDATE = os.path.join(DATA_DIR, \"experiment_model1/base_validate.txt\")\n",
    "FILE_BASE_TEST     = os.path.join(DATA_DIR, \"experiment_model1/base_test.txt\")\n",
    "\n",
    "\n",
    "\n",
    "# COMBINATIONS OF FIELDS (all combinations include Baseline, i.e. feature 1)\n",
    "\n",
    "# Datasets with field: WORDS + POS TAGS only\n",
    "FILE_POS_TRAIN    = os.path.join(DATA_DIR, \"experiment_model1/pos_train.txt\")\n",
    "FILE_POS_VALIDATE = os.path.join(DATA_DIR, \"experiment_model1/pos_validate.txt\")\n",
    "FILE_POS_TEST     = os.path.join(DATA_DIR, \"experiment_model1/pos_test.txt\")\n",
    "\n",
    "# Datasets with field: WORDS + POS BIGRAMS only\n",
    "FILE_BIGRAM_TRAIN    = os.path.join(DATA_DIR, \"experiment_model1/bigram_train.txt\")\n",
    "FILE_BIGRAM_VALIDATE = os.path.join(DATA_DIR, \"experiment_model1/bigram_validate.txt\")\n",
    "FILE_BIGRAM_TEST     = os.path.join(DATA_DIR, \"experiment_model1/bigram_test.txt\")\n",
    "\n",
    "# Datasets with field: WORDS + POS TRIGRAMS only\n",
    "FILE_TRIGRAM_TRAIN    = os.path.join(DATA_DIR, \"experiment_model1/trigram_train.txt\")\n",
    "FILE_TRIGRAM_VALIDATE = os.path.join(DATA_DIR, \"experiment_model1/trigram_validate.txt\")\n",
    "FILE_TRIGRAM_TEST     = os.path.join(DATA_DIR, \"experiment_model1/trigram_test.txt\")\n",
    "\n",
    "# Datasets with field: WORDS + PRODUCTIONS only\n",
    "FILE_PROD_TRAIN    = os.path.join(DATA_DIR, \"experiment_model1/prod_train.txt\")\n",
    "FILE_PROD_VALIDATE = os.path.join(DATA_DIR, \"experiment_model1/prod_validate.txt\")\n",
    "FILE_PROD_TEST     = os.path.join(DATA_DIR, \"experiment_model1/prod_test.txt\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Datasets with field: WORDS + POS BIGRAMS + POS TRIGRAMS only\n",
    "FILE_BIGRAM_TRIGRAM_TRAIN    = os.path.join(DATA_DIR, \"experiment_model1/bigram_trigram_train.txt\")\n",
    "FILE_BIGRAM_TRIGRAM_VALIDATE = os.path.join(DATA_DIR, \"experiment_model1/bigram_trigram_validate.txt\")\n",
    "FILE_BIGRAM_TRIGRAM_TEST     = os.path.join(DATA_DIR, \"experiment_model1/bigram_trigram_test.txt\")\n",
    "\n",
    "# Datasets with field: WORDS + POS + POS BIGRAMS + POS TRIGRAMS only\n",
    "FILE_POS_BIGRAM_TRIGRAM_TRAIN    = os.path.join(DATA_DIR, \"experiment_model1/pos_bigram_trigram_train.txt\")\n",
    "FILE_POS_BIGRAM_TRIGRAM_VALIDATE = os.path.join(DATA_DIR, \"experiment_model1/pos_bigram_trigram_validate.txt\")\n",
    "FILE_POS_BIGRAM_TRIGRAM_TEST     = os.path.join(DATA_DIR, \"experiment_model1/pos_bigram_trigram_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_pos(data_type):\n",
    "    \"\"\"\n",
    "    For Model 1, define the file path for the dataset with parts of speech features\n",
    "    Parameters:\n",
    "        data_type: One of the following strings:\n",
    "            train, validate, test\n",
    "    Return:\n",
    "        FILE_READ: path of file to be read\n",
    "        FILE_WRITE: path of file to write to\n",
    "    \"\"\"\n",
    "    if data_type == 'train':\n",
    "        FILE_READ = FILE_MODEL1_TRAIN\n",
    "        FILE_WRITE = FILE_POS_TRAIN\n",
    "        \n",
    "    elif data_type == 'validate':   \n",
    "        FILE_READ = FILE_MODEL1_VALIDATE\n",
    "        FILE_WRITE = FILE_POS_VALIDATE\n",
    "        \n",
    "    elif data_type == 'test':\n",
    "        FILE_READ = FILE_MODEL1_TEST\n",
    "        FILE_WRITE = FILE_POS_TEST\n",
    "        \n",
    "    return FILE_READ, FILE_WRITE   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_bigram(data_type):\n",
    "    \"\"\"\n",
    "    For Model 1, define the file path for the dataset with POS bigram features\n",
    "    Parameters:\n",
    "        data_type: One of the following strings:\n",
    "            train, validate, test\n",
    "    Return:\n",
    "        FILE_READ: path of file to be read\n",
    "        FILE_WRITE: path of file to write to\n",
    "    \"\"\"\n",
    "    if data_type == 'train':\n",
    "        FILE_READ = FILE_MODEL1_TRAIN\n",
    "        FILE_WRITE = FILE_BIGRAM_TRAIN\n",
    "        \n",
    "    elif data_type == 'validate':   \n",
    "        FILE_READ = FILE_MODEL1_VALIDATE\n",
    "        FILE_WRITE = FILE_BIGRAM_VALIDATE\n",
    "        \n",
    "    elif data_type == 'test':\n",
    "        FILE_READ = FILE_MODEL1_TEST\n",
    "        FILE_WRITE = FILE_BIGRAM_TEST\n",
    "        \n",
    "    return FILE_READ, FILE_WRITE   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_trigram(data_type):\n",
    "    \"\"\"\n",
    "    For Model 1, define the file path for the dataset with words trigram features\n",
    "    Parameters:\n",
    "        data_type: One of the following strings:\n",
    "            train, validate, test\n",
    "    Return:\n",
    "        FILE_READ: path of file to be read\n",
    "        FILE_WRITE: path of file to write to\n",
    "    \"\"\"    \n",
    "    if data_type == 'train':\n",
    "        FILE_READ = FILE_MODEL1_TRAIN\n",
    "        FILE_WRITE = FILE_TRIGRAM_TRAIN\n",
    "        \n",
    "    elif data_type == 'validate':   \n",
    "        FILE_READ = FILE_MODEL1_VALIDATE\n",
    "        FILE_WRITE = FILE_TRIGRAM_VALIDATE\n",
    "        \n",
    "    elif data_type == 'test':\n",
    "        FILE_READ = FILE_MODEL1_TEST\n",
    "        FILE_WRITE = FILE_TRIGRAM_TEST\n",
    "        \n",
    "    return FILE_READ, FILE_WRITE   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_prod(data_type):\n",
    "    \"\"\"\n",
    "    For Model 1, define the file path for the dataset with production features\n",
    "    Parameters:\n",
    "        data_type: One of the following strings:\n",
    "            train, validate, test\n",
    "    Return:\n",
    "        FILE_READ: path of file to be read\n",
    "        FILE_WRITE: path of file to write to\n",
    "    \"\"\"        \n",
    "    if data_type == 'train':\n",
    "        FILE_READ = FILE_MODEL1_TRAIN\n",
    "        FILE_WRITE = FILE_PROD_TRAIN\n",
    "        \n",
    "    elif data_type == 'validate':   \n",
    "        FILE_READ = FILE_MODEL1_VALIDATE\n",
    "        FILE_WRITE = FILE_PROD_VALIDATE\n",
    "        \n",
    "    elif data_type == 'test':\n",
    "        FILE_READ = FILE_MODEL1_TEST\n",
    "        FILE_WRITE = FILE_PROD_TEST\n",
    "        \n",
    "    return FILE_READ, FILE_WRITE   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_bigram_trigram(data_type):\n",
    "    \"\"\"\n",
    "    For Model 1, define the file path for the dataset with words bigram and trigram features\n",
    "    Parameters:\n",
    "        data_type: One of the following strings:\n",
    "            train, validate, test\n",
    "    Return:\n",
    "        FILE_READ: path of file to be read\n",
    "        FILE_WRITE: path of file to write to\n",
    "    \"\"\"        \n",
    "    if data_type == 'train':\n",
    "        FILE_READ = FILE_MODEL1_TRAIN\n",
    "        FILE_WRITE = FILE_BIGRAM_TRIGRAM_TRAIN\n",
    "        \n",
    "    elif data_type == 'validate':   \n",
    "        FILE_READ = FILE_MODEL1_VALIDATE\n",
    "        FILE_WRITE = FILE_BIGRAM_TRIGRAM_VALIDATE\n",
    "        \n",
    "    elif data_type == 'test':\n",
    "        FILE_READ = FILE_MODEL1_TEST\n",
    "        FILE_WRITE = FILE_BIGRAM_TRIGRAM_TEST\n",
    "        \n",
    "    return FILE_READ, FILE_WRITE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_pos_bigram_trigram(data_type):\n",
    "    \"\"\"\n",
    "    For Model 1, define the file path for the dataset with POS bigram and trigram features\n",
    "    Parameters:\n",
    "        data_type: One of the following strings:\n",
    "            train, validate, test\n",
    "    Return:\n",
    "        FILE_READ: path of file to be read\n",
    "        FILE_WRITE: path of file to write to\n",
    "    \"\"\"            \n",
    "    if data_type == 'train':\n",
    "        FILE_READ = FILE_MODEL1_TRAIN\n",
    "        FILE_WRITE = FILE_POS_BIGRAM_TRIGRAM_TRAIN\n",
    "        \n",
    "    elif data_type == 'validate':   \n",
    "        FILE_READ = FILE_MODEL1_VALIDATE\n",
    "        FILE_WRITE = FILE_POS_BIGRAM_TRIGRAM_VALIDATE\n",
    "        \n",
    "    elif data_type == 'test':\n",
    "        FILE_READ = FILE_MODEL1_TEST\n",
    "        FILE_WRITE = FILE_POS_BIGRAM_TRIGRAM_TEST\n",
    "        \n",
    "    return FILE_READ, FILE_WRITE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_base(data_type):\n",
    "    \"\"\"\n",
    "    For Model 1, define the file path for the dataset with features for baseline model\n",
    "    Parameters:\n",
    "        data_type: One of the following strings:\n",
    "            train, validate, test\n",
    "    Return:\n",
    "        FILE_READ: path of file to be read\n",
    "        FILE_WRITE: path of file to write to\n",
    "    \"\"\"                \n",
    "    if data_type == 'train':\n",
    "        FILE_READ = FILE_MODEL1_TRAIN\n",
    "        FILE_WRITE = FILE_BASE_TRAIN\n",
    "        \n",
    "    elif data_type == 'validate':   \n",
    "        FILE_READ = FILE_MODEL1_VALIDATE\n",
    "        FILE_WRITE = FILE_BASE_VALIDATE\n",
    "        \n",
    "    elif data_type == 'test':\n",
    "        FILE_READ = FILE_MODEL1_TEST\n",
    "        FILE_WRITE = FILE_BASE_TEST\n",
    "        \n",
    "    return FILE_READ, FILE_WRITE   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_dataset(FILE_READ, FILE_WRITE, model):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        FILE_READ: file path of dataset to be read\n",
    "        FILE_WRITE: file path of dataset to write to\n",
    "        \n",
    "    A Model 1 record:\n",
    "    index 0: 0 \n",
    "    index 1: qid:9007 \n",
    "    index 2: 1:8.108303  \n",
    "    \n",
    "    index 3:   2:1.7645977       pos \n",
    "    index 4:   3:1.3150331       bi\n",
    "    index 5:   4:0.0             tri\n",
    "    index 6:   5:4.730212       prod\n",
    "    \n",
    "    index 7: # \n",
    "    index 8: docid:436\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    data_list_final = []\n",
    "    \n",
    "    if model=='base':\n",
    "        index_list = [1,2,7]   \n",
    "\n",
    "    if model=='pos':\n",
    "        index_list = [1,2,3,7]   \n",
    "\n",
    "    elif model=='bi':\n",
    "        index_list = [1,2,4,7]  \n",
    "\n",
    "    elif model=='tri':\n",
    "        index_list = [1,2,5,7]  \n",
    "    \n",
    "    elif model=='bitri':\n",
    "        index_list = [1,2,4,5,7]   \n",
    "\n",
    "    elif model=='pos_bitri':\n",
    "        index_list = [1,2,3,4,5,7] \n",
    "     \n",
    "    elif model=='prod':\n",
    "        index_list = [1,2,6,7]\n",
    "    \n",
    "\n",
    "        \n",
    "    with open(FILE_READ, 'r') as fread:\n",
    "        for line in fread:\n",
    "            data_list.append(line)\n",
    "\n",
    "    for i, record in enumerate(data_list):\n",
    "        \n",
    "        record_list = record.split()\n",
    "        \n",
    "        for k, feature in enumerate(record_list):\n",
    "            \n",
    "            if k==0:\n",
    "                data_list_final.append(feature)\n",
    "                \n",
    "            elif k in index_list:\n",
    "                data_list_final[i] += ' ' + feature\n",
    "                \n",
    "            elif k==8:\n",
    "                data_list_final[i] += ' ' + feature + '\\n' \n",
    "                \n",
    "    with open(FILE_WRITE, 'w') as fwrite:\n",
    "        for x in data_list_final:\n",
    "            fwrite.write(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RUN!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_READ, FILE_WRITE = get_data_pos('train')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'pos')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_pos('validate')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'pos')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_pos('test')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_READ, FILE_WRITE = get_data_bigram('train')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'bi')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_bigram('validate')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'bi')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_bigram('test')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'bi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_READ, FILE_WRITE = get_data_trigram('train')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'tri')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_trigram('validate')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'tri')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_trigram('test')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'tri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_READ, FILE_WRITE = get_data_prod('train')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'prod')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_prod('validate')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'prod')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_prod('test')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'prod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_READ, FILE_WRITE = get_data_bigram_trigram('train')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'bitri')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_bigram_trigram('validate')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'bitri')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_bigram_trigram('test')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'bitri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_READ, FILE_WRITE = get_data_pos_bigram_trigram('train')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'pos_bitri')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_pos_bigram_trigram('validate')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'pos_bitri')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_pos_bigram_trigram('test')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'pos_bitri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_READ, FILE_WRITE = get_data_base('train')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'base')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_base('validate')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'base')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_base('test')  \n",
    "experiment_dataset(FILE_READ, FILE_WRITE, 'base')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

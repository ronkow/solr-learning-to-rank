{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **FEATURE VALUE EXTRACTION (BY SOLR) AND ADDING RELEVANCE LABELS TO DATASETS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random    # random.randint\n",
    "import os        # os.path.join\n",
    "import csv       # csv.DictReader\n",
    "import json      # json.dumps\n",
    "import requests  # requests.post\n",
    "import urllib    # urllib.parse.urlencode, urllib.parse.quote_plus\n",
    "import re        # re.match\n",
    "import solr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATA PATHS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR   = \"data/\"\n",
    "\n",
    "FEATURE_QUERY_TRAIN = os.path.join(DATA_DIR, \"feature/feature_query.csv\")\n",
    "FEATURE_QUERY_VALIDATE_TEST = os.path.join(DATA_DIR, \"feature/feature_query_validate_test.csv\")\n",
    "\n",
    "FEATURE_FILE_TEMPLATE_MODEL1 = os.path.join(DATA_DIR, \"model/no_relevance_model1_{:s}.txt\")\n",
    "FEATURE_FILE_TEMPLATE_MODEL2 = os.path.join(DATA_DIR, \"model/no_relevance_model2_{:s}.txt\")\n",
    "\n",
    "\n",
    "FILE_MODEL1_NO_RELEVANCE_TRAIN    = os.path.join(DATA_DIR, \"model/no_relevance_model1_train.txt\")\n",
    "FILE_MODEL1_NO_RELEVANCE_VALIDATE = os.path.join(DATA_DIR, \"model/no_relevance_model1_validate.txt\")\n",
    "FILE_MODEL1_NO_RELEVANCE_TEST     = os.path.join(DATA_DIR, \"model/no_relevance_model1_test.txt\")\n",
    "\n",
    "FILE_MODEL2_NO_RELEVANCE_TRAIN    = os.path.join(DATA_DIR, \"model/no_relevance_model2_train.txt\")\n",
    "FILE_MODEL2_NO_RELEVANCE_VALIDATE = os.path.join(DATA_DIR, \"model/no_relevance_model2_validate.txt\")\n",
    "FILE_MODEL2_NO_RELEVANCE_TEST     = os.path.join(DATA_DIR, \"model/no_relevance_model2_test.txt\")\n",
    "\n",
    "\n",
    "FILE_MODEL1_TRAIN    = os.path.join(DATA_DIR, \"model/model1_train.txt\")\n",
    "FILE_MODEL1_VALIDATE = os.path.join(DATA_DIR, \"model/model1_validate.txt\")\n",
    "FILE_MODEL1_TEST     = os.path.join(DATA_DIR, \"model/model1_test.txt\")\n",
    "\n",
    "FILE_MODEL2_TRAIN    = os.path.join(DATA_DIR, \"model/model2_train.txt\")\n",
    "FILE_MODEL2_VALIDATE = os.path.join(DATA_DIR, \"model/model2_validate.txt\")\n",
    "FILE_MODEL2_TEST     = os.path.join(DATA_DIR, \"model/model2_test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GLOBAL VARIABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOLR_URL = \"http://localhost:8983/solr/core1\"\n",
    "\n",
    "FEAT_SUFFIXES = [\"train\", \"validate\", \"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CREATE DATASETS in LETOR FORMAT for MODELS 1 AND 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_letor(qid, feat_string, docid, FEATURE_LIST):\n",
    "    \"\"\"\n",
    "    Format a row in the input dataset\n",
    "    Parameters:\n",
    "        qid: id of query\n",
    "        feat_string: feature ids and values\n",
    "        docid: id of document\n",
    "        FEATURE_LIST: list of feature names\n",
    "    Return:\n",
    "       A string of the following format:\n",
    "           qid:xxx feature_id1:feature_value1 feature_id2: feature_value2... # docid:yyy\n",
    "    \"\"\"\n",
    "    feat_pairs = []\n",
    "    feature_name_to_id = {name: idx + 1 for idx, name in enumerate(FEATURE_LIST)}\n",
    "    \n",
    "    for feat_nv in feat_string.split(','):\n",
    "        feat_name, feat_value = feat_nv.split('=')\n",
    "        \n",
    "        feat_id = str(feature_name_to_id[feat_name])\n",
    "               \n",
    "        feat_value = float(feat_value)\n",
    "        feat_value = str(feat_value)\n",
    "        \n",
    "        feat_pairs.append( ':'.join([feat_id, feat_value]) )\n",
    "\n",
    "    return f\"qid:{qid} {' '.join(feat_pairs)} # docid:{docid}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_query_lists():\n",
    "    \"\"\"\n",
    "    Convert the CSV files for queries (training, validation/testing) into lists\n",
    "    Split the validation/testing lists into separate validation and test queries\n",
    "    Return:\n",
    "        train_q: list of queries for training\n",
    "        validate_q: list of queries for validation\n",
    "        test_q: list of queries for testing\n",
    "    \"\"\"\n",
    "    with open(FEATURE_QUERY_TRAIN) as f1:\n",
    "        QUERY_LIST_TRAIN = [ {k: v for k, v in row.items()} for row in csv.DictReader(f1, skipinitialspace=True) ]\n",
    "\n",
    "    with open(FEATURE_QUERY_VALIDATE_TEST) as f2:\n",
    "        QUERY_LIST_VALIDATE_TEST = [ {k: v for k, v in row.items()} for row in csv.DictReader(f2, skipinitialspace=True) ]\n",
    "    \n",
    "    random.seed(1)\n",
    "    random.shuffle(QUERY_LIST_VALIDATE_TEST)\n",
    "       \n",
    "    train_q    = QUERY_LIST_TRAIN\n",
    "    validate_q = QUERY_LIST_VALIDATE_TEST[0:75]\n",
    "    test_q     = QUERY_LIST_VALIDATE_TEST[75:]\n",
    "    \n",
    "    return train_q, validate_q, test_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_solr(payload):\n",
    "    \"\"\"\n",
    "    Send the payload to Solr\n",
    "    Parameter:\n",
    "        payload: payload in JSON format\n",
    "    Return:\n",
    "        docs: response containing document ids, feature values\n",
    "    \"\"\"\n",
    "    params = urllib.parse.urlencode(payload, quote_via=urllib.parse.quote_plus)\n",
    "    search_url = SOLR_URL + \"/query?\" + params\n",
    "    resp = requests.get(search_url)\n",
    "    resp_json = json.loads(resp.text)\n",
    "    docs = resp_json[\"response\"][\"docs\"]\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model1_data(FEATURE_LIST, train_q, validate_q, test_q):\n",
    "    \"\"\"\n",
    "    Create the payload in JSON format for Model 1 to be sent to Solr\n",
    "    Formats the response in LETOR dataset format\n",
    "    Paramaters:\n",
    "        FEATURE_LIST: list of feature names\n",
    "        train_q: list of queries for training\n",
    "        validation_q: list of queries for validation\n",
    "        test_q: list of queries for testing\n",
    "    Calls:\n",
    "        query_solr(payload)\n",
    "        format_letor(qid, feat_string, docid, FEATURE_LIST)\n",
    "    \"\"\"\n",
    "   \n",
    "\n",
    "    qid = 1\n",
    "    for i, queries in enumerate([train_q, validate_q, test_q]):    #[(0,'train_q'), (1,'validate_q'), (2,'test_q')]\n",
    "    \n",
    "        model_data_file = open(FEATURE_FILE_TEMPLATE_MODEL1.format(FEAT_SUFFIXES[i]), \"w\")\n",
    "\n",
    "        for q in queries:\n",
    "            f1 = q[\"qa\"]\n",
    "            f2 = q[\"qa_pos\"]\n",
    "            f3 = q[\"qa_pos_bigram\"]\n",
    "            f4 = q[\"qa_pos_trigram\"]\n",
    "            f5 = q[\"qa_parse_tree\"]\n",
    "                          \n",
    "            payload = {\n",
    "                \"q\": f1,\n",
    "                \"defType\": \"edismax\",\n",
    "                \"qf\": \"qa\",\n",
    "                \"rq\": f'{{!ltr model=linear_model1 \\\n",
    "                    efi.q2=\"{f2}\" \\\n",
    "                    efi.q3=\"{f3}\" \\\n",
    "                    efi.q4=\"{f4}\" \\\n",
    "                    efi.q5=\"{f5}\"}}',\n",
    "                \"fl\": \"id,[features]\",   \n",
    "                \"rows\": 50,\n",
    "            }\n",
    "                        \n",
    "            docs = query_solr(payload) \n",
    "                        \n",
    "            for doc in docs:\n",
    "                docid = int(doc[\"id\"])            \n",
    "                feat_string = doc[\"[features]\"]\n",
    "                qid = int(q[\"id\"])\n",
    "                model_data_file.write( \"{:s}\\n\".format( format_letor(qid, feat_string, docid, FEATURE_LIST) ) )  ###\n",
    "                \n",
    "        model_data_file.close()\n",
    "\n",
    "    print(f\"MODEL 1: number of queries: train {len(train_q)}, validation {len(validate_q)}, test {len(test_q)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model2_data(FEATURE_LIST, train_q, validate_q, test_q):\n",
    "    \"\"\"\n",
    "    Create the payload in JSON format for Model 2 to be sent to Solr\n",
    "    Formats the response in LETOR dataset format\n",
    "    Paramaters:\n",
    "        FEATURE_LIST: list of feature names\n",
    "        train_q: list of queries for training\n",
    "        validation_q: list of queries for validation\n",
    "        test_q: list of queries for testing\n",
    "    Calls:\n",
    "        query_solr(payload)\n",
    "        format_letor(qid, feat_string, docid, FEATURE_LIST)\n",
    "    \"\"\"\n",
    "    \n",
    "    qid = 1\n",
    "    for i, queries in enumerate([train_q, validate_q, test_q]):   \n",
    "    \n",
    "        model_data_file = open(FEATURE_FILE_TEMPLATE_MODEL2.format(FEAT_SUFFIXES[i]), \"w\")\n",
    "\n",
    "        for q in queries:\n",
    "            f1 = q[\"ss\"]\n",
    "            f2 = q[\"ss_pos\"]\n",
    "            f3 = q[\"ss_pos_bigram\"]\n",
    "            f4 = q[\"ss_pos_trigram\"]\n",
    "            f5 = q[\"ss_parse_tree\"]\n",
    "            f6 = q[\"before\"]\n",
    "            f7 = q[\"before_last\"]\n",
    "            f8 = (q[\"before_last_pos\"]).lower()\n",
    "            f9 = q[\"before_pos\"]\n",
    "            f10 = q[\"before_pos_bigram\"]\n",
    "            f11 = q[\"before_pos_trigram\"]\n",
    "            f12 = q[\"before_parse_tree\"]\n",
    "            f13 = q[\"after\"]\n",
    "            f14 = q[\"after_first\"]\n",
    "            f15 = (q[\"after_first_pos\"]).lower()\n",
    "            f16 = q[\"after_pos\"]\n",
    "            f17 = q[\"after_pos_bigram\"]\n",
    "            f18 = q[\"after_pos_trigram\"]\n",
    "            f19 = q[\"after_parse_tree\"]\n",
    "            f20 = q[\"ans\"]\n",
    "            f21 = q[\"ans_first\"]\n",
    "            f22 = q[\"ans_last\"]\n",
    "            f23 = (q[\"ans_pos\"]).lower()\n",
    "            f24 = (q[\"ans_first_pos\"]).lower()\n",
    "            f25 = (q[\"ans_last_pos\"]).lower()\n",
    "            f26 = q[\"ans_is_first\"]\n",
    "            f27 = q[\"ans_is_last\"]\n",
    "            f28 = q[\"ans_length\"]\n",
    "            f_topic = str(q[\"qb_topic_id\"])\n",
    "            \n",
    "            payload = {\n",
    "                \"q\": f1,\n",
    "                \"defType\": \"edismax\",\n",
    "                \"qf\": \"ss\",\n",
    "                \"rq\": f'{{!ltr model=linear_model2 \\\n",
    "                    efi.q2=\"{f2}\" \\\n",
    "                    efi.q3=\"{f3}\" \\\n",
    "                    efi.q4=\"{f4}\" \\\n",
    "                    efi.q5=\"{f5}\" \\\n",
    "                    efi.q6=\"{f6}\" \\\n",
    "                    efi.q7=\"{f7}\" \\\n",
    "                    efi.q8=\"{f8}\" \\\n",
    "                    efi.q9=\"{f9}\" \\\n",
    "                    efi.q10=\"{f10}\" \\\n",
    "                    efi.q11=\"{f11}\" \\\n",
    "                    efi.q12=\"{f12}\" \\\n",
    "                    efi.q13=\"{f13}\" \\\n",
    "                    efi.q14=\"{f14}\" \\\n",
    "                    efi.q15=\"{f15}\" \\\n",
    "                    efi.q16=\"{f16}\" \\\n",
    "                    efi.q17=\"{f17}\" \\\n",
    "                    efi.q18=\"{f18}\" \\\n",
    "                    efi.q19=\"{f19}\" \\\n",
    "                    efi.q20=\"{f20}\" \\\n",
    "                    efi.q21=\"{f21}\" \\\n",
    "                    efi.q22=\"{f22}\" \\\n",
    "                    efi.q23=\"{f23}\" \\\n",
    "                    efi.q24=\"{f24}\" \\\n",
    "                    efi.q25=\"{f25}\" \\\n",
    "                    efi.q26=\"{f26}\" \\\n",
    "                    efi.q27=\"{f27}\" \\\n",
    "                    efi.q28=\"{f28}\" \\\n",
    "                    efi.q_topic=\"{f_topic}\"}}',\n",
    "                \"fl\": \"score,id,[features]\",   \n",
    "                \"rows\": 50\n",
    "            }\n",
    "            \n",
    "            docs = query_solr(payload) \n",
    "            \n",
    "            for doc in docs:\n",
    "                docid = int(doc[\"id\"])            \n",
    "                feat_string = doc[\"[features]\"]\n",
    "                qid = int(q[\"id\"])\n",
    "                model_data_file.write( \"{:s}\\n\".format( format_letor(qid, feat_string, docid, FEATURE_LIST) ) )  \n",
    "            \n",
    "        model_data_file.close()\n",
    "\n",
    "    print(f\"MODEL 2: number of queries: train {len(train_q)}, validation {len(validate_q)}, test {len(test_q)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **COMPUTE and PREPEND RELEVANCE LABELS IN DATASETS** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_type, model):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        data_type: one of the following strings:\n",
    "            train, validate, test\n",
    "        model: one of the following integers:\n",
    "            1: for Model 1\n",
    "            2: for Model 2\n",
    "    Return: \n",
    "        FILE_READ: file path of file to be read\n",
    "        FILE_WRITE: file path to write to\n",
    "    \"\"\"\n",
    "    if model==1:\n",
    "        if data_type == 'train':\n",
    "            FILE_READ = FILE_MODEL1_NO_RELEVANCE_TRAIN\n",
    "            FILE_WRITE = FILE_MODEL1_TRAIN\n",
    "        \n",
    "        elif data_type == 'validate':   \n",
    "            FILE_READ = FILE_MODEL1_NO_RELEVANCE_VALIDATE\n",
    "            FILE_WRITE = FILE_MODEL1_VALIDATE\n",
    "        \n",
    "        elif data_type == 'test':\n",
    "            FILE_READ = FILE_MODEL1_NO_RELEVANCE_TEST\n",
    "            FILE_WRITE = FILE_MODEL1_TEST\n",
    "\n",
    "    elif model==2:\n",
    "        if data_type == 'train':\n",
    "            FILE_READ = FILE_MODEL2_NO_RELEVANCE_TRAIN\n",
    "            FILE_WRITE = FILE_MODEL2_TRAIN\n",
    "        \n",
    "        elif data_type == 'validate':   \n",
    "            FILE_READ = FILE_MODEL2_NO_RELEVANCE_VALIDATE\n",
    "            FILE_WRITE = FILE_MODEL2_VALIDATE\n",
    "        \n",
    "        elif data_type == 'test':\n",
    "            FILE_READ = FILE_MODEL2_NO_RELEVANCE_TEST\n",
    "            FILE_WRITE = FILE_MODEL2_TEST\n",
    "\n",
    "    return FILE_READ, FILE_WRITE        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training, validation and test datasets created so far do not have the relevance label as the first item\n",
    "# We prepend this relevance label here\n",
    "\n",
    "def prepend_relevance_label_model1(FILE_READ, FILE_WRITE):\n",
    "    \"\"\"\n",
    "    Prepend the relevance label to the dataset for Model 1\n",
    "    Parameters:\n",
    "        FILE_READ: file path for dataset to be read\n",
    "        FILE_WRITE: file path to write to\n",
    "\n",
    "    RELEVANCE = 1 if these feature values are >= 3.0:\n",
    "    qa_pos           (feature 2)  \n",
    "    qa_pos_bigram    (feature 3)     \n",
    "    qa_pos_trigram   (feature 4)\n",
    "    qa_parse_tree    (feature 5)    \n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    \n",
    "    with open(FILE_READ, 'r') as fread:\n",
    "        for line in fread:\n",
    "            data_list.append(line)\n",
    "\n",
    "    for i, record in enumerate(data_list):\n",
    "        record_list = record.split()\n",
    "        match=0\n",
    "        score=0\n",
    "        \n",
    "        for k, feature in enumerate(record_list):\n",
    "            if k==2 or k==3 or k==4 or k==5:\n",
    "                pattern1 = fr'^{k}:0\\.'\n",
    "                pattern2 = fr'^{k}:1\\.'\n",
    "                pattern3 = fr'^{k}:2\\.'\n",
    "                \n",
    "                match1 = re.match(pattern1,feature)\n",
    "                match2 = re.match(pattern2,feature)\n",
    "                match3 = re.match(pattern3,feature)\n",
    "                \n",
    "                if not match1 and not match2 and not match3:\n",
    "                    match = 1\n",
    "                else:\n",
    "                    match = 0\n",
    "                    \n",
    "                score += match\n",
    "                    \n",
    "        if score==4:\n",
    "            relevance = 1\n",
    "        else:\n",
    "            relevance = 0\n",
    "        \n",
    "        data_list[i] = str(relevance) + ' ' + record\n",
    "\n",
    "    with open(FILE_WRITE, 'w') as fwrite:\n",
    "        for x in data_list:\n",
    "            fwrite.write(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepend_relevance_label_model2(FILE_READ, FILE_WRITE):\n",
    "    \"\"\"\n",
    "    Prepend the relevance label to the dataset for Model 2\n",
    "    Parameters:\n",
    "        FILE_READ: file path for dataset to be read\n",
    "        FILE_WRITE: file path to write to\n",
    "    \n",
    "    RELEVANCE = 1 if:\n",
    "    ans_last_pos  (feature 25)  \n",
    "    ans_length    (feature 28)     \n",
    "    qb_topic_id   (feature 29)\n",
    "\n",
    "    REVEVANCE = 2 if, additionally:\n",
    "    ans_first_pos (feature 24)\n",
    "\n",
    "    RELEVANCE = 3 if, additionally:\n",
    "    ans_first     (feature 21)\n",
    "    ans_last      (feature 22)\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    \n",
    "    with open(FILE_READ, 'r') as fread:\n",
    "        for line in fread:\n",
    "            data_list.append(line)\n",
    "\n",
    "    for i, record in enumerate(data_list):\n",
    "        record_list = record.split()\n",
    "        match=0\n",
    "        score1=0\n",
    "        score2=0\n",
    "        score3=0\n",
    "        score4=0\n",
    "        \n",
    "        for k, feature in enumerate(record_list):\n",
    "            if k==21 or k==22 or k==23 or k==24 or k==25 or k==28 or k==29:\n",
    "                pattern = fr'^{k}:0'\n",
    "                match = re.match(pattern,feature)\n",
    "                \n",
    "                if not match:\n",
    "                    match = 1\n",
    "                else:\n",
    "                    match = 0\n",
    "                \n",
    "                if k==25 or k==28 or k==29:\n",
    "                    score1 += match\n",
    "                elif k==24:\n",
    "                    score2 += match\n",
    "                elif k==21 or k==22:    \n",
    "                    score3 += match\n",
    "                    \n",
    "        if score3==2 and score2==1 and score1==3:\n",
    "            relevance = 3\n",
    "        elif score3!=2 and score2==1 and score1==3:\n",
    "            relevance = 2\n",
    "        elif score3!=2 and score2!=1 and score1==3:\n",
    "            relevance = 1\n",
    "        else:\n",
    "            relevance = 0\n",
    "        \n",
    "        record = record.replace('29:0.0 ','')\n",
    "        record = record.replace('29:1.0 ','')\n",
    "        data_list[i] = str(relevance) + ' ' + record\n",
    "\n",
    "    with open(FILE_WRITE, 'w') as fwrite:\n",
    "        for x in data_list:\n",
    "            fwrite.write(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RUN!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATASETS WITH NO RELEVANCE LABELS** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 1: number of queries: train 152, validation 75, test 77\n",
      "MODEL 2: number of queries: train 152, validation 75, test 77\n"
     ]
    }
   ],
   "source": [
    "train_q, validate_q, test_q = create_query_lists()\n",
    "\n",
    "FEATURE_LIST_ONE = solr.feature_list(1)\n",
    "FEATURE_LIST_TWO = solr.feature_list(2)\n",
    "\n",
    "create_model1_data(FEATURE_LIST_ONE, train_q, validate_q, test_q)\n",
    "create_model2_data(FEATURE_LIST_TWO, train_q, validate_q, test_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PREPEND RELEVANCE LABELS** ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 1\n",
    "FILE_READ, FILE_WRITE = get_data('train', 1)  \n",
    "prepend_relevance_label_model1(FILE_READ, FILE_WRITE)\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data('validate', 1)  \n",
    "prepend_relevance_label_model1(FILE_READ, FILE_WRITE)\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data('test', 1)  \n",
    "prepend_relevance_label_model1(FILE_READ, FILE_WRITE)\n",
    "\n",
    "# MODEL 2\n",
    "FILE_READ, FILE_WRITE = get_data('train', 2)  \n",
    "prepend_relevance_label_model2(FILE_READ, FILE_WRITE)\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data('validate', 2)  \n",
    "prepend_relevance_label_model2(FILE_READ, FILE_WRITE)\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data('test', 2)  \n",
    "prepend_relevance_label_model2(FILE_READ, FILE_WRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATA PATHS, GLOBAL VARIABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR   = \"data/\"\n",
    "\n",
    "# Model 2 datasets\n",
    "FILE_MODEL2_TRAIN    = os.path.join(DATA_DIR, \"final/model2_train.txt\")\n",
    "FILE_MODEL2_VALIDATE = os.path.join(DATA_DIR, \"final/model2_validate.txt\")\n",
    "FILE_MODEL2_TEST     = os.path.join(DATA_DIR, \"final/model2_test.txt\")\n",
    "\n",
    "# Datasets with fields: ss, before, after, ans; with no parse tree features\n",
    "FILE_NO_PARSETREE_TRAIN    = os.path.join(DATA_DIR, \"experiment/no_parsetree_train.txt\")\n",
    "FILE_NO_PARSETREE_VALIDATE = os.path.join(DATA_DIR, \"experiment/no_parsetree_validate.txt\")\n",
    "FILE_NO_PARSETREE_TEST     = os.path.join(DATA_DIR, \"experiment/no_parsetree_test.txt\")\n",
    "\n",
    "# Datasets with fields: ss, before, after, ans; with no bigram and trigram features\n",
    "FILE_NO_NGRAM_TRAIN    = os.path.join(DATA_DIR, \"experiment/no_ngram_train.txt\")\n",
    "FILE_NO_NGRAM_VALIDATE = os.path.join(DATA_DIR, \"experiment/no_ngram_validate.txt\")\n",
    "FILE_NO_NGRAM_TEST     = os.path.join(DATA_DIR, \"experiment/no_ngram_test.txt\")\n",
    "\n",
    "# Datasets with field ss only\n",
    "FILE_SS_TRAIN    = os.path.join(DATA_DIR, \"experiment/ss_train.txt\")\n",
    "FILE_SS_VALIDATE = os.path.join(DATA_DIR, \"experiment/ss_validate.txt\")\n",
    "FILE_SS_TEST     = os.path.join(DATA_DIR, \"experiment/ss_test.txt\")\n",
    "\n",
    "# Datasets with field ans only\n",
    "FILE_ANS_TRAIN    = os.path.join(DATA_DIR, \"experiment/ans_train.txt\")\n",
    "FILE_ANS_VALIDATE = os.path.join(DATA_DIR, \"experiment/ans_validate.txt\")\n",
    "FILE_ANS_TEST     = os.path.join(DATA_DIR, \"experiment/ans_test.txt\")\n",
    "\n",
    "# Datasets with fields before, after only\n",
    "FILE_BEFORE_AFTER_TRAIN    = os.path.join(DATA_DIR, \"experiment/before_after_train.txt\")\n",
    "FILE_BEFORE_AFTER_VALIDATE = os.path.join(DATA_DIR, \"experiment/before_after_validate.txt\")\n",
    "FILE_BEFORE_AFTER_TEST     = os.path.join(DATA_DIR, \"experiment/before_after_test.txt\")\n",
    "\n",
    "# Datasets with fields ans, before, after only\n",
    "FILE_ANS_BEFORE_AFTER_TRAIN    = os.path.join(DATA_DIR, \"experiment/ans_before_after_train.txt\")\n",
    "FILE_ANS_BEFORE_AFTER_VALIDATE = os.path.join(DATA_DIR, \"experiment/ans_before_after_validate.txt\")\n",
    "FILE_ANS_BEFORE_AFTER_TEST     = os.path.join(DATA_DIR, \"experiment/ans_before_after_test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATASETS FOR MODEL WITH ALL FIELDS but NO PARSE TREES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_no_parse_tree(data_type):\n",
    "    \n",
    "    if data_type == 'train':\n",
    "        FILE_READ = FILE_MODEL2_TRAIN\n",
    "        FILE_WRITE = FILE_NO_PARSETREE_TRAIN\n",
    "        \n",
    "    elif data_type == 'validate':   \n",
    "        FILE_READ = FILE_MODEL2_VALIDATE\n",
    "        FILE_WRITE = FILE_NO_PARSETREE_VALIDATE\n",
    "        \n",
    "    elif data_type == 'test':\n",
    "        FILE_READ = FILE_MODEL2_TEST\n",
    "        FILE_WRITE = FILE_NO_PARSETREE_TEST\n",
    "        \n",
    "    return FILE_READ, FILE_WRITE        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATASETS FOR MODEL WITH ALL FIELDS but NO NGRAMS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_no_ngram(data_type):\n",
    "    \n",
    "    if data_type == 'train':\n",
    "        FILE_READ = FILE_MODEL2_TRAIN\n",
    "        FILE_WRITE = FILE_NO_NGRAM_TRAIN\n",
    "        \n",
    "    elif data_type == 'validate':   \n",
    "        FILE_READ = FILE_MODEL2_VALIDATE\n",
    "        FILE_WRITE = FILE_NO_NGRAM_VALIDATE\n",
    "        \n",
    "    elif data_type == 'test':\n",
    "        FILE_READ = FILE_MODEL2_TEST\n",
    "        FILE_WRITE = FILE_NO_NGRAM_TEST\n",
    "        \n",
    "    return FILE_READ, FILE_WRITE    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATASETS FOR MODEL WITH FIELDS: BASELINE + SUBSTRING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_ss(data_type):\n",
    "    \n",
    "    if data_type == 'train':\n",
    "        FILE_READ = FILE_MODEL2_TRAIN\n",
    "        FILE_WRITE = FILE_SS_TRAIN\n",
    "        \n",
    "    elif data_type == 'validate':   \n",
    "        FILE_READ = FILE_MODEL2_VALIDATE\n",
    "        FILE_WRITE = FILE_SS_VALIDATE\n",
    "        \n",
    "    elif data_type == 'test':\n",
    "        FILE_READ = FILE_MODEL2_TEST\n",
    "        FILE_WRITE = FILE_SS_TEST\n",
    "        \n",
    "    return FILE_READ, FILE_WRITE        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATASETS FOR MODEL WITH FIELDS: BASELINE + ANS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_ans(data_type):\n",
    "    \n",
    "    if data_type == 'train':\n",
    "        FILE_READ = FILE_MODEL2_TRAIN\n",
    "        FILE_WRITE = FILE_ANS_TRAIN\n",
    "        \n",
    "    elif data_type == 'validate':   \n",
    "        FILE_READ = FILE_MODEL2_VALIDATE\n",
    "        FILE_WRITE = FILE_ANS_VALIDATE\n",
    "        \n",
    "    elif data_type == 'test':\n",
    "        FILE_READ = FILE_MODEL2_TEST\n",
    "        FILE_WRITE = FILE_ANS_TEST\n",
    "        \n",
    "    return FILE_READ, FILE_WRITE        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATASETS FOR MODEL WITH FIELDS: BASELINE + BEFORE, AFTER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_before_after(data_type):\n",
    "    \n",
    "    if data_type == 'train':\n",
    "        FILE_READ = FILE_MODEL2_TRAIN\n",
    "        FILE_WRITE = FILE_BEFORE_AFTER_TRAIN\n",
    "        \n",
    "    elif data_type == 'validate':   \n",
    "        FILE_READ = FILE_MODEL2_VALIDATE\n",
    "        FILE_WRITE = FILE_BEFORE_AFTER_VALIDATE\n",
    "        \n",
    "    elif data_type == 'test':\n",
    "        FILE_READ = FILE_MODEL2_TEST\n",
    "        FILE_WRITE = FILE_BEFORE_AFTER_TEST\n",
    "        \n",
    "    return FILE_READ, FILE_WRITE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATASETS FOR MODEL WITH FIELDS: BASELINE + ANS, BEFORE, AFTER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_ans_before_after(data_type):\n",
    "    \n",
    "    if data_type == 'train':\n",
    "        FILE_READ = FILE_MODEL2_TRAIN\n",
    "        FILE_WRITE = FILE_ANS_BEFORE_AFTER_TRAIN\n",
    "        \n",
    "    elif data_type == 'validate':   \n",
    "        FILE_READ = FILE_MODEL2_VALIDATE\n",
    "        FILE_WRITE = FILE_ANS_BEFORE_AFTER_VALIDATE\n",
    "        \n",
    "    elif data_type == 'test':\n",
    "        FILE_READ = FILE_MODEL2_TEST\n",
    "        FILE_WRITE = FILE_ANS_BEFORE_AFTER_TEST\n",
    "        \n",
    "    return FILE_READ, FILE_WRITE   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_experiment(FILE_TEMP, FILE_WRITE, model):\n",
    "    \"\"\"\n",
    "    A Model 2 record:\n",
    "    0 qid:9007 \n",
    "    field ss:     1:8.108303  2:1.7645977 3:1.3150331 4:0.0         5:4.730212 \n",
    "    field before: 6:1.4057359 7:0.0       8:0.0       9:0.44799113  10:0.0     11:0.0   12:1.2664754 \n",
    "    field after:  13:0.0      14:0.0      15:0.0      16:1.2265432  17:0.0     18:0.0   19:1.1179526 \n",
    "    field ans:    20:0.0      21:0.0      22:0.0      23:0.0        24:0.0     25:1.0   26:0.0       27:0.0  28:0.0 \n",
    "    # docid:436\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    data_list_final = []\n",
    "    \n",
    "    if model=='ans':\n",
    "        index_list = [1,2,21,22,23,24,25,26,27,28,29,30]   # features 20 to 28\n",
    "    \n",
    "    elif model=='ans_before_after':\n",
    "        index_list = [1,2,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]    # features 6 to 12, 13 to 19, 20 to 38\n",
    "    \n",
    "    elif model=='before_after':\n",
    "        index_list = [1,2,7,8,9,10,11,12,13,14,15,16,17,18,19,20,30]   # features 6 to 12, 13 to 19\n",
    "    \n",
    "    elif model=='ss':\n",
    "        index_list = [1,2,3,4,5,6,30]   # features 1 to 5\n",
    "        \n",
    "    elif model=='no_parse_tree':\n",
    "        index_list = [1,2,3,4,5,7,8,9,10,11,12,14,15,16,17,18,19,21,22,23,24,25,26,27,28,29,30]  # exclude features 5, 12, 19\n",
    "\n",
    "    elif model=='no_ngram':\n",
    "        index_list = [1,2,3,6,7,8,9,10,13,14,15,16,17,20,21,22,23,24,25,26,27,28,29,30]   # exclude features 3, 4, 10, 11, 17, 18\n",
    " \n",
    "\n",
    "    with open(FILE_READ, 'r') as fread:\n",
    "        for line in fread:\n",
    "            data_list.append(line)\n",
    "\n",
    "    for i, record in enumerate(data_list):\n",
    "        \n",
    "        record_list = record.split()\n",
    "        \n",
    "        for k, feature in enumerate(record_list):\n",
    "            \n",
    "            if k==0:\n",
    "                data_list_final.append(feature)\n",
    "                \n",
    "            elif k in index_list:\n",
    "                data_list_final[i] += ' ' + feature\n",
    "                \n",
    "            elif k==31:\n",
    "                data_list_final[i] += ' ' + feature + '\\n' \n",
    "                \n",
    "    with open(FILE_WRITE, 'w') as fwrite:\n",
    "        for x in data_list_final:\n",
    "            fwrite.write(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_READ, FILE_WRITE = get_data_no_ngram('train')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'no_ngram')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_no_ngram('validate')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'no_ngram')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_no_ngram('test')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'no_ngram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_READ, FILE_WRITE = get_data_no_parse_tree('train')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'no_parse_tree')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_no_parse_tree('validate')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'no_parse_tree')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_no_parse_tree('test')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'no_parse_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_READ, FILE_WRITE = get_data_ss('train')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'ss')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_ss('validate')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'ss')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_ss('test')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'ss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_READ, FILE_WRITE = get_data_ans('train')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'ans')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_ans('validate')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'ans')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_ans('test')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'ans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_READ, FILE_WRITE = get_data_before_after('train')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'before_after')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_before_after('validate')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'before_after')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_before_after('test')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'before_after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_READ, FILE_WRITE = get_data_ans_before_after('train')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'ans_before_after')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_ans_before_after('validate')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'ans_before_after')\n",
    "\n",
    "FILE_READ, FILE_WRITE = get_data_ans_before_after('test')  \n",
    "dataset_experiment(FILE_READ, FILE_WRITE, 'ans_before_after')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

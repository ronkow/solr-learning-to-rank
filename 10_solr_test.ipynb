{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random    \n",
    "import os        \n",
    "import csv       \n",
    "import json      \n",
    "import requests  \n",
    "import urllib    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATA PATHS, GLOBAL VARIABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR  = \"data/\"\n",
    "FEATURE_QUERY_VALIDATE_TEST = os.path.join(DATA_DIR, \"feature_query_validate_test.csv\")\n",
    "\n",
    "SOLR_URL = \"http://localhost:8983/solr/core1\"\n",
    "\n",
    "N = 10    # Top N results to display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GET A RANDOM QUERY FROM THE VALIDATION_TEST DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_query(myseed):\n",
    "    \"\"\"\n",
    "    Select a random query from the query/validation dataset\n",
    "    Parameter:\n",
    "        myseed: seed value\n",
    "    \"\"\"\n",
    "    with open(FEATURE_QUERY_VALIDATE_TEST) as f:\n",
    "        QUERY_LIST = [ {k: v for k, v in row.items()} for row in csv.DictReader(f, skipinitialspace=True) ]\n",
    "    \n",
    "    random.seed(myseed)\n",
    "    random.shuffle(QUERY_LIST)\n",
    "       \n",
    "    query = QUERY_LIST[0]  \n",
    "    return query   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HELPER FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_results(docs, query, ans, topic, top_n):\n",
    "\n",
    "    print(f\"Top {top_n} results for the query: {query} (answer: {ans}, topic: {topic})\\n\")\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc_id = int(doc[\"id\"])\n",
    "        qb_question = doc[\"qb_question\"][0]                   # solr indexed the data as a list! Can this be fixed?\n",
    "        qb_answer = doc[\"qb_answer\"][0]\n",
    "        qb_topic_id = doc[\"qb_topic_id\"][0]\n",
    "        print(f\"doc_id: {doc_id} \\t {qb_question} ({qb_answer})(topic: {qb_topic_id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_solr(payload):\n",
    "    \n",
    "    params = urllib.parse.urlencode(payload, quote_via=urllib.parse.quote_plus)\n",
    "    search_url = SOLR_URL + \"/query?\" + params\n",
    "    resp = requests.get(search_url)\n",
    "    resp_json = json.loads(resp.text)\n",
    "    docs = resp_json[\"response\"][\"docs\"]\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PAYLOAD TO QUERY SOLR BY DEFAULT BM25 (ENTIRE SENTENCE or SUBSTRING)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODEL: Default Solr (entire sentence)\n",
    "\n",
    "def run_query_default_qa(q):\n",
    "       \n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "    \n",
    "    query = q['qa']\n",
    "    \n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"qa\",\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N\n",
    "    }\n",
    "\n",
    "    docs = query_solr(payload)\n",
    "    print(\"QUERY: ENTIRE SENTENCE, ANSWER NOT INDICATED\\n\")\n",
    "    print(\"Default Solr results:\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODEL: Default Solr (substring)\n",
    "\n",
    "def run_query_default_ss(q):\n",
    "       \n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "    \n",
    "    query = q['ss']\n",
    "    \n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"ss\",\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N\n",
    "    }\n",
    "\n",
    "    docs = query_solr(payload)\n",
    "    print(\"QUERY: SUBSTRING, ANSWER INDICATED\\n\")\n",
    "    print(\"Default Solr results:\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PAYLOAD TO QUERY SOLR USING LAMBDAMART BASELINE MODELS**\n",
    "#### Baseline models only have one feature: BM25 for entire sentence (Model 1) or BM25 for substring (Model 2)\n",
    "\n",
    "#### When we enable LTR, Solr will rerank the original results from default BM25 (i.e when no LTR models are used)\n",
    "#### By default, Solr reranks the top 200 results.\n",
    "#### But we can set the number N of reranks by setting the `reRankDocs` parameter, for example, to rerank only the top 10 results:\n",
    "`\"rq\": f'{{!ltr model=lambdamart_model1 reRankDocs=10 ...}}',`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LTR BASELINE MODEL 1 (entire sentence)\n",
    "\n",
    "def run_query_lambdamart_baseline_model1(q):\n",
    "    \n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "\n",
    "    query = q['qa']\n",
    "\n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"qa\",\n",
    "        \"rq\": f'{{!ltr model=lambdamart_model1_baseline}}',\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N\n",
    "    }\n",
    "\n",
    "    docs = query_solr(payload)\n",
    "    print(\"LTR Baseline Model 1 results:\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LTR BASELINE MODEL 2 (substring)\n",
    "\n",
    "def run_query_lambdamart_baseline_model2(q):\n",
    "    \n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "\n",
    "    query = q['ss']\n",
    "\n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"ss\",\n",
    "        \"rq\": f'{{!ltr model=lambdamart_model2_baseline}}',\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N\n",
    "    }\n",
    "\n",
    "    docs = query_solr(payload)\n",
    "    print(\"LTR Baseline Model 2 results:\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PAYLOAD TO QUERY SOLR USING LAMBDAMART MODELS 1 AND 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LTR MODEL 1\n",
    "\n",
    "def run_query_lambdamart_model1(q):\n",
    "\n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "\n",
    "    query = q['qa']\n",
    "    f2 = q[\"qa_pos\"]\n",
    "    f3 = q[\"qa_pos_bigram\"]\n",
    "    f4 = q[\"qa_pos_trigram\"]\n",
    "    f5 = q[\"qa_parse_tree\"]\n",
    "    \n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"qa\",\n",
    "        \"rq\": f'{{!ltr model=lambdamart_model1 \\\n",
    "        efi.q2=\"{f2}\" \\\n",
    "        efi.q3=\"{f3}\" \\\n",
    "        efi.q4=\"{f4}\" \\\n",
    "        efi.q5=\"{f5}\"}}',\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N\n",
    "    }\n",
    "\n",
    "    docs = query_solr(payload)\n",
    "    print(\"LTR Model 1 results:\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LTR MODEL 2\n",
    "\n",
    "def run_query_lambdamart_model2(q):\n",
    "    \n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "\n",
    "    query = q['ss']\n",
    "    f2 = q[\"ss_pos\"]\n",
    "    f3 = q[\"ss_pos_bigram\"]\n",
    "    f4 = q[\"ss_pos_trigram\"]\n",
    "    f5 = q[\"ss_parse_tree\"]\n",
    "    f6 = q[\"before\"]\n",
    "    f7 = q[\"before_last\"]\n",
    "    f8 = (q[\"before_last_pos\"]).lower()\n",
    "    f9 = q[\"before_pos\"]\n",
    "    f10 = q[\"before_pos_bigram\"]\n",
    "    f11 = q[\"before_pos_trigram\"]\n",
    "    f12 = q[\"before_parse_tree\"]\n",
    "    f13 = q[\"after\"]\n",
    "    f14 = q[\"after_first\"]\n",
    "    f15 = (q[\"after_first_pos\"]).lower()\n",
    "    f16 = q[\"after_pos\"]\n",
    "    f17 = q[\"after_pos_bigram\"]\n",
    "    f18 = q[\"after_pos_trigram\"]\n",
    "    f19 = q[\"after_parse_tree\"]\n",
    "    f20 = q[\"ans\"]\n",
    "    f21 = q[\"ans_first\"]\n",
    "    f22 = q[\"ans_last\"]\n",
    "    f23 = (q[\"ans_pos\"]).lower()\n",
    "    f24 = (q[\"ans_first_pos\"]).lower()\n",
    "    f25 = (q[\"ans_last_pos\"]).lower()\n",
    "    f26 = q[\"ans_is_first\"]\n",
    "    f27 = q[\"ans_is_last\"]\n",
    "    f28 = q[\"ans_length\"]\n",
    "    \n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"ss\",\n",
    "        \"rq\": f'{{!ltr model=lambdamart_model2 \\\n",
    "        efi.q2=\"{f2}\" \\\n",
    "        efi.q3=\"{f3}\" \\\n",
    "        efi.q4=\"{f4}\" \\\n",
    "        efi.q5=\"{f5}\" \\\n",
    "        efi.q6=\"{f6}\" \\\n",
    "        efi.q7=\"{f7}\" \\\n",
    "        efi.q8=\"{f8}\" \\\n",
    "        efi.q9=\"{f9}\" \\\n",
    "        efi.q10=\"{f10}\" \\\n",
    "        efi.q11=\"{f11}\" \\\n",
    "        efi.q12=\"{f12}\" \\\n",
    "        efi.q13=\"{f13}\" \\\n",
    "        efi.q14=\"{f14}\" \\\n",
    "        efi.q15=\"{f15}\" \\\n",
    "        efi.q16=\"{f16}\" \\\n",
    "        efi.q17=\"{f17}\" \\\n",
    "        efi.q18=\"{f18}\" \\\n",
    "        efi.q19=\"{f19}\" \\\n",
    "        efi.q20=\"{f20}\" \\\n",
    "        efi.q21=\"{f21}\" \\\n",
    "        efi.q22=\"{f22}\" \\\n",
    "        efi.q23=\"{f23}\" \\\n",
    "        efi.q24=\"{f24}\" \\\n",
    "        efi.q25=\"{f25}\" \\\n",
    "        efi.q26=\"{f26}\" \\\n",
    "        efi.q27=\"{f27}\" \\\n",
    "        efi.q28=\"{f28}\"}}',\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N,\n",
    "    }\n",
    "    \n",
    "    docs = query_solr(payload)\n",
    "    print(\"LTR Model 1 results:\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TESTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '9129',\n",
       " 'qb_question': \"I can * myself so you don't have to be concerned.\",\n",
       " 'qb_answer': 'look after',\n",
       " 'qb_topic_id': '3',\n",
       " 'qa': \"I can look after myself so you don't have to be concerned.\",\n",
       " 'qa_pos': 'PRP MD VB IN PRP RB PRP VBP VB TO VB JJ',\n",
       " 'qa_pos_bigram': 'PRP_MD MD_VB VB_IN IN_PRP PRP_RB RB_PRP PRP_VBP VBP_VB VB_TO TO_VB VB_JJ',\n",
       " 'qa_pos_trigram': 'PRP_MD_VB MD_VB_IN VB_IN_PRP IN_PRP_RB PRP_RB_PRP RB_PRP_VBP PRP_VBP_VB VBP_VB_TO VB_TO_VB TO_VB_JJ',\n",
       " 'qa_parse_tree': 'S_PRN_ADVP_NP_VP_. PRN_S S_NP_VP NP_PRP VP_MD_VP VP_VB_PP PP_IN_NP NP_PRP ADVP_RB NP_PRP VP_VBP_RB_VP VP_VB_S S_VP VP_TO_VP VP_VB_VP VP_VBN',\n",
       " 'ss': \"I can look after myself so you don't\",\n",
       " 'ss_pos': 'PRP MD VB IN PRP RB PRP VBP',\n",
       " 'ss_pos_bigram': 'PRP_MD MD_VB VB_IN IN_PRP PRP_RB RB_PRP PRP_VBP',\n",
       " 'ss_pos_trigram': 'PRP_MD_VB MD_VB_IN VB_IN_PRP IN_PRP_RB PRP_RB_PRP RB_PRP_VBP',\n",
       " 'ss_parse_tree': 'S_PRN_NP_VP PRN_S S_NP_VP NP_PRP VP_MD_VP VP_VB_PP_ADVP PP_IN_NP NP_PRP ADVP_RB NP_PRP VP_VBP_RB',\n",
       " 'before': 'I can',\n",
       " 'before_last': 'can',\n",
       " 'before_last_pos': 'MD',\n",
       " 'before_pos': 'PRP MD',\n",
       " 'before_pos_bigram': 'PRP_MD',\n",
       " 'before_pos_trigram': '',\n",
       " 'before_parse_tree': 'S_NP_VP NP_PRP VP_MD',\n",
       " 'after': \"myself so you don't\",\n",
       " 'after_first': 'myself',\n",
       " 'after_first_pos': 'PRP',\n",
       " 'after_pos': 'PRP RB PRP VBP',\n",
       " 'after_pos_bigram': 'PRP_RB RB_PRP PRP_VBP',\n",
       " 'after_pos_trigram': 'PRP_RB_PRP RB_PRP_VBP',\n",
       " 'after_parse_tree': 'S_NP_NP_VP NP_PRP NP_RB_PRP VP_VBP_RB',\n",
       " 'ans': 'look after',\n",
       " 'ans_first': 'look',\n",
       " 'ans_last': 'after',\n",
       " 'ans_pos': 'NN_IN',\n",
       " 'ans_first_pos': 'NN',\n",
       " 'ans_last_pos': 'IN',\n",
       " 'ans_is_first': 'y',\n",
       " 'ans_is_last': 'y',\n",
       " 'ans_length': '2.0'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_random_query(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: ENTIRE SENTENCE, ANSWER NOT INDICATED\n",
      "\n",
      "Default Solr results:\n",
      "Top 10 results for the query: I can look after myself so you don't have to be concerned. (answer: look after, topic: 3)\n",
      "\n",
      "doc_id: 392 \t She is very independent. She can * herself. (look after)(topic: 3)\n",
      "doc_id: 393 \t I hope you will * my garden when I am gone. (look after)(topic: 3)\n",
      "doc_id: 826 \t Be careful when you handle the knife. Don't cut *. (yourself)(topic: 5)\n",
      "doc_id: 273 \t I know I should have waited for you * I was so hungry just now. (but)(topic: 2)\n",
      "doc_id: 822 \t I finished the work all by * after three long months. (myself)(topic: 5)\n",
      "doc_id: 233 \t You will not be able to cancel this contract * you have signed it. (once)(topic: 2)\n",
      "doc_id: 60 \t Thank you for your consideration. I look forward to hearing * you. (from)(topic: 1)\n",
      "doc_id: 692 \t This time next month, I * myself in Paris. (will be enjoying)(topic: 4)\n",
      "doc_id: 259 \t You can come to me * you need help. (whenever)(topic: 2)\n",
      "doc_id: 206 \t I need to talk to you * you are done with your work. (after)(topic: 2)\n",
      "\n",
      "LTR Baseline Model 1 results:\n",
      "Top 10 results for the query: I can look after myself so you don't have to be concerned. (answer: look after, topic: 3)\n",
      "\n",
      "doc_id: 393 \t I hope you will * my garden when I am gone. (look after)(topic: 3)\n",
      "doc_id: 392 \t She is very independent. She can * herself. (look after)(topic: 3)\n",
      "doc_id: 60 \t Thank you for your consideration. I look forward to hearing * you. (from)(topic: 1)\n",
      "doc_id: 273 \t I know I should have waited for you * I was so hungry just now. (but)(topic: 2)\n",
      "doc_id: 692 \t This time next month, I * myself in Paris. (will be enjoying)(topic: 4)\n",
      "doc_id: 822 \t I finished the work all by * after three long months. (myself)(topic: 5)\n",
      "doc_id: 826 \t Be careful when you handle the knife. Don't cut *. (yourself)(topic: 5)\n",
      "doc_id: 233 \t You will not be able to cancel this contract * you have signed it. (once)(topic: 2)\n",
      "doc_id: 206 \t I need to talk to you * you are done with your work. (after)(topic: 2)\n",
      "doc_id: 259 \t You can come to me * you need help. (whenever)(topic: 2)\n",
      "\n",
      "LTR Model 1 results:\n",
      "Top 10 results for the query: I can look after myself so you don't have to be concerned. (answer: look after, topic: 3)\n",
      "\n",
      "doc_id: 10 \t I will be in Tokyo * two weeks. (for)(topic: 1)\n",
      "doc_id: 209 \t Soon * we set off, the car began to make strange noises. (after)(topic: 2)\n",
      "doc_id: 276 \t There was a nation-wide manhunt, * he was nowhere to be found. (but)(topic: 2)\n",
      "doc_id: 278 \t They don't serve coffee, * they have tea. (but)(topic: 2)\n",
      "doc_id: 292 \t I will regret it * I don't do this now. (if)(topic: 2)\n",
      "doc_id: 291 \t We will miss the train * we don't hurry. (if)(topic: 2)\n",
      "doc_id: 346 \t You cannot go to the party unless I *. (come along)(topic: 3)\n",
      "doc_id: 384 \t You will have to * your rifles before the new gun laws take effect. (turn in)(topic: 3)\n",
      "doc_id: 382 \t I am feeling sleepy so I will * now. (turn in)(topic: 3)\n",
      "doc_id: 422 \t I hope things will start to * when this pandemic is over. (look up)(topic: 3)\n",
      "\n",
      "QUERY: SUBSTRING, ANSWER INDICATED\n",
      "\n",
      "Default Solr results:\n",
      "Top 10 results for the query: I can look after myself so you don't (answer: look after, topic: 3)\n",
      "\n",
      "doc_id: 392 \t She is very independent. She can * herself. (look after)(topic: 3)\n",
      "doc_id: 393 \t I hope you will * my garden when I am gone. (look after)(topic: 3)\n",
      "doc_id: 744 \t Can you show * where I can find a good supermarket? (me)(topic: 5)\n",
      "doc_id: 414 \t I will * how we can improve the work processes. (look into)(topic: 3)\n",
      "doc_id: 394 \t I * my neighbour's dog when he is away for business. (look after)(topic: 3)\n",
      "doc_id: 210 \t I went home immediately * I met you. (after)(topic: 2)\n",
      "doc_id: 822 \t I finished the work all by * after three long months. (myself)(topic: 5)\n",
      "doc_id: 474 \t I am counting on you. Please don't *. (let me down)(topic: 3)\n",
      "doc_id: 718 \t Don't worry, * will not be blamed for this mess your team members created. (you)(topic: 5)\n",
      "doc_id: 273 \t I know I should have waited for you * I was so hungry just now. (but)(topic: 2)\n",
      "\n",
      "LTR Baseline Model 2 results:\n",
      "Top 10 results for the query: I can look after myself so you don't (answer: look after, topic: 3)\n",
      "\n",
      "doc_id: 392 \t She is very independent. She can * herself. (look after)(topic: 3)\n",
      "doc_id: 393 \t I hope you will * my garden when I am gone. (look after)(topic: 3)\n",
      "doc_id: 744 \t Can you show * where I can find a good supermarket? (me)(topic: 5)\n",
      "doc_id: 210 \t I went home immediately * I met you. (after)(topic: 2)\n",
      "doc_id: 491 \t If you * so easily, you will never succeed. (give up)(topic: 3)\n",
      "doc_id: 273 \t I know I should have waited for you * I was so hungry just now. (but)(topic: 2)\n",
      "doc_id: 474 \t I am counting on you. Please don't *. (let me down)(topic: 3)\n",
      "doc_id: 718 \t Don't worry, * will not be blamed for this mess your team members created. (you)(topic: 5)\n",
      "doc_id: 822 \t I finished the work all by * after three long months. (myself)(topic: 5)\n",
      "doc_id: 394 \t I * my neighbour's dog when he is away for business. (look after)(topic: 3)\n",
      "\n",
      "LTR Model 1 results:\n",
      "Top 10 results for the query: I can look after myself so you don't (answer: look after, topic: 3)\n",
      "\n",
      "doc_id: 394 \t I * my neighbour's dog when he is away for business. (look after)(topic: 3)\n",
      "doc_id: 393 \t I hope you will * my garden when I am gone. (look after)(topic: 3)\n",
      "doc_id: 395 \t The nurses * the patients very well in this hospital. (look after)(topic: 3)\n",
      "doc_id: 392 \t She is very independent. She can * herself. (look after)(topic: 3)\n",
      "doc_id: 420 \t I was asked to * the report before sending it for approval. (look over)(topic: 3)\n",
      "doc_id: 384 \t You will have to * your rifles before the new gun laws take effect. (turn in)(topic: 3)\n",
      "doc_id: 414 \t I will * how we can improve the work processes. (look into)(topic: 3)\n",
      "doc_id: 415 \t I hope the government will * the alleged fraud. (look into)(topic: 3)\n",
      "doc_id: 413 \t If you really * it, you will find that this is the best offer you will get. (look into)(topic: 3)\n",
      "doc_id: 314 \t He * in a rash after eating oranges. (broke out)(topic: 3)\n"
     ]
    }
   ],
   "source": [
    "query = select_random_query(8)\n",
    "\n",
    "run_query_default_qa(query)\n",
    "print('')\n",
    "run_query_lambdamart_baseline_model1(query)\n",
    "print('')\n",
    "run_query_lambdamart_model1(query)\n",
    "print('')\n",
    "\n",
    "run_query_default_ss(query)\n",
    "print('')\n",
    "run_query_lambdamart_baseline_model2(query)\n",
    "print('')\n",
    "run_query_lambdamart_model2(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

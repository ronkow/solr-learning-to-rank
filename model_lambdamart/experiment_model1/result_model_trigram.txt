java -jar RankLib-2.14.jar -train ../data/experiment/trigram_train.txt -test ../data/experiment/trigram_test.txt -validate ../data/experiment/trigram_validate.txt -ranker 6 -metric2t MAP -metric2T MAP -save ../model/experiment/model_trigram.txt -gmax 1

Discard orig. features
Training data:	../data/experiment/trigram_train.txt
Test data:	../data/experiment/trigram_test.txt
Validation data:	../data/experiment/trigram_validate.txt
Feature vector representation: Dense.
Ranking method:	LambdaMART
Feature description file:	Unspecified. All features will be used.
Train metric:	MAP
Test metric:	MAP
Feature normalization: No
Model file: ../model/experiment/model_trigram.txt

[+] LambdaMART's Parameters:
No. of trees: 1000
No. of leaves: 10
No. of threshold candidates: 256
Min leaf support: 1
Learning rate: 0.1
Stop early: 100 rounds without performance gain on validation data

Reading feature file [../data/experiment/trigram_train.txt]... [Done.]            
(152 ranked lists, 7600 entries read)
Reading feature file [../data/experiment/trigram_validate.txt]... [Done.]            
(75 ranked lists, 3750 entries read)
Reading feature file [../data/experiment/trigram_test.txt]... [Done.]            
(77 ranked lists, 3850 entries read)
Initializing... [Done]
---------------------------------
Training starts...
---------------------------------
#iter   | MAP-T     | MAP-V     | 
---------------------------------
1       | 0.4262    | 0.4343    | 
2       | 0.4337    | 0.4386    | 
3       | 0.4341    | 0.4386    | 
4       | 0.7189    | 0.7289    | 
5       | 0.7575    | 0.7758    | 
6       | 0.7561    | 0.7744    | 
7       | 0.7566    | 0.7744    | 
8       | 0.7567    | 0.7744    | 
9       | 0.7567    | 0.7744    | 
10      | 0.7567    | 0.7744    | 
11      | 0.763     | 0.7778    | 
12      | 0.7639    | 0.7775    | 
13      | 0.764     | 0.7756    | 
14      | 0.7744    | 0.7763    | 
15      | 0.7741    | 0.7763    | 
16      | 0.7774    | 0.7797    | 
17      | 0.776     | 0.7803    | 
18      | 0.7836    | 0.7894    | 
19      | 0.7831    | 0.7869    | 
20      | 0.7823    | 0.7866    | 
21      | 0.7835    | 0.7846    | 
22      | 0.7841    | 0.7864    | 
23      | 0.7868    | 0.7911    | 
24      | 0.7858    | 0.791     | 
25      | 0.7879    | 0.7894    | 
26      | 0.7867    | 0.7876    | 
27      | 0.7893    | 0.7894    | 
28      | 0.7912    | 0.7877    | 
29      | 0.7911    | 0.7874    | 
30      | 0.7945    | 0.7886    | 
31      | 0.7964    | 0.7905    | 
32      | 0.7942    | 0.7916    | 
33      | 0.7945    | 0.793     | 
34      | 0.7957    | 0.7942    | 
35      | 0.7977    | 0.7948    | 
36      | 0.797     | 0.7939    | 
37      | 0.7973    | 0.7952    | 
38      | 0.7993    | 0.7961    | 
39      | 0.7984    | 0.7943    | 
40      | 0.7969    | 0.7931    | 
41      | 0.7972    | 0.7923    | 
42      | 0.7981    | 0.793     | 
43      | 0.7979    | 0.7931    | 
44      | 0.7989    | 0.7927    | 
45      | 0.7986    | 0.7921    | 
46      | 0.7979    | 0.7918    | 
47      | 0.799     | 0.7925    | 
48      | 0.7981    | 0.7908    | 
49      | 0.7979    | 0.7907    | 
50      | 0.7985    | 0.7917    | 
51      | 0.7984    | 0.7919    | 
52      | 0.7998    | 0.7923    | 
53      | 0.7991    | 0.7916    | 
54      | 0.8004    | 0.7946    | 
55      | 0.804     | 0.7942    | 
56      | 0.8039    | 0.7942    | 
57      | 0.8051    | 0.7933    | 
58      | 0.8049    | 0.7934    | 
59      | 0.8049    | 0.794     | 
60      | 0.8048    | 0.7937    | 
61      | 0.8043    | 0.7937    | 
62      | 0.804     | 0.793     | 
63      | 0.8067    | 0.7929    | 
64      | 0.806     | 0.7927    | 
65      | 0.8068    | 0.8008    | 
66      | 0.8077    | 0.7998    | 
67      | 0.8074    | 0.7998    | 
68      | 0.8073    | 0.7994    | 
69      | 0.8072    | 0.7997    | 
70      | 0.8075    | 0.8007    | 
71      | 0.8073    | 0.8006    | 
72      | 0.8075    | 0.7992    | 
73      | 0.8072    | 0.7994    | 
74      | 0.8077    | 0.7999    | 
75      | 0.8081    | 0.7999    | 
76      | 0.8085    | 0.7989    | 
77      | 0.8081    | 0.7989    | 
78      | 0.8077    | 0.799     | 
79      | 0.8075    | 0.7987    | 
80      | 0.8082    | 0.7986    | 
81      | 0.8082    | 0.7988    | 
82      | 0.808     | 0.7988    | 
83      | 0.8078    | 0.7988    | 
84      | 0.8078    | 0.7998    | 
85      | 0.8076    | 0.8003    | 
86      | 0.8077    | 0.8009    | 
87      | 0.8078    | 0.8011    | 
88      | 0.808     | 0.8022    | 
89      | 0.8074    | 0.8023    | 
90      | 0.8079    | 0.8031    | 
91      | 0.8073    | 0.8025    | 
92      | 0.8077    | 0.8019    | 
93      | 0.8081    | 0.8028    | 
94      | 0.8081    | 0.8019    | 
95      | 0.808     | 0.8021    | 
96      | 0.8084    | 0.8028    | 
97      | 0.8084    | 0.8024    | 
98      | 0.8077    | 0.8022    | 
99      | 0.8083    | 0.8023    | 
100     | 0.8084    | 0.8024    | 
101     | 0.8088    | 0.8024    | 
102     | 0.8086    | 0.8024    | 
103     | 0.8085    | 0.8023    | 
104     | 0.8074    | 0.8023    | 
105     | 0.8071    | 0.8023    | 
106     | 0.8066    | 0.8014    | 
107     | 0.8071    | 0.8012    | 
108     | 0.8071    | 0.8012    | 
109     | 0.8071    | 0.8013    | 
110     | 0.8062    | 0.8004    | 
111     | 0.8057    | 0.8004    | 
112     | 0.8058    | 0.8004    | 
113     | 0.8055    | 0.8004    | 
114     | 0.8053    | 0.8004    | 
115     | 0.8054    | 0.8002    | 
116     | 0.8054    | 0.8004    | 
117     | 0.8052    | 0.8002    | 
118     | 0.8052    | 0.7996    | 
119     | 0.8051    | 0.7994    | 
120     | 0.8057    | 0.7992    | 
121     | 0.8045    | 0.7993    | 
122     | 0.8046    | 0.7986    | 
123     | 0.8045    | 0.7987    | 
124     | 0.8051    | 0.7982    | 
125     | 0.8045    | 0.7982    | 
126     | 0.8045    | 0.7982    | 
127     | 0.8054    | 0.7985    | 
128     | 0.8058    | 0.7987    | 
129     | 0.8046    | 0.7964    | 
130     | 0.8048    | 0.7961    | 
131     | 0.8044    | 0.796     | 
132     | 0.8047    | 0.7964    | 
133     | 0.8047    | 0.7968    | 
134     | 0.8054    | 0.798     | 
135     | 0.805     | 0.7982    | 
136     | 0.805     | 0.7982    | 
137     | 0.8058    | 0.7982    | 
138     | 0.8054    | 0.7966    | 
139     | 0.8048    | 0.7969    | 
140     | 0.8049    | 0.7967    | 
141     | 0.8034    | 0.7944    | 
142     | 0.8033    | 0.7948    | 
143     | 0.8035    | 0.7947    | 
144     | 0.8026    | 0.7938    | 
145     | 0.8031    | 0.7962    | 
146     | 0.8034    | 0.7959    | 
147     | 0.8035    | 0.7992    | 
148     | 0.8037    | 0.7991    | 
149     | 0.8017    | 0.798     | 
150     | 0.8015    | 0.7981    | 
151     | 0.8017    | 0.7985    | 
152     | 0.8018    | 0.7985    | 
153     | 0.8017    | 0.7985    | 
154     | 0.8011    | 0.7971    | 
155     | 0.8013    | 0.7974    | 
156     | 0.8014    | 0.7975    | 
157     | 0.8011    | 0.7941    | 
158     | 0.8013    | 0.7973    | 
159     | 0.8013    | 0.7972    | 
160     | 0.8001    | 0.7974    | 
161     | 0.8008    | 0.7974    | 
162     | 0.7996    | 0.7971    | 
163     | 0.7997    | 0.7973    | 
164     | 0.7995    | 0.7976    | 
165     | 0.8001    | 0.7983    | 
166     | 0.8001    | 0.7983    | 
167     | 0.7992    | 0.7973    | 
168     | 0.7987    | 0.7972    | 
169     | 0.7988    | 0.7973    | 
170     | 0.7988    | 0.7973    | 
171     | 0.7992    | 0.7973    | 
172     | 0.7989    | 0.7974    | 
173     | 0.7981    | 0.7972    | 
174     | 0.7983    | 0.7973    | 
175     | 0.7978    | 0.7972    | 
176     | 0.7977    | 0.7973    | 
177     | 0.7974    | 0.7975    | 
178     | 0.7977    | 0.7961    | 
179     | 0.7985    | 0.7964    | 
180     | 0.7978    | 0.7962    | 
181     | 0.798     | 0.7963    | 
182     | 0.7978    | 0.7961    | 
183     | 0.7977    | 0.7961    | 
184     | 0.7977    | 0.7962    | 
185     | 0.7983    | 0.7962    | 
186     | 0.7981    | 0.7962    | 
187     | 0.7982    | 0.7964    | 
188     | 0.7974    | 0.7958    | 
189     | 0.7974    | 0.7959    | 
190     | 0.7976    | 0.7962    | 
191     | 0.7975    | 0.7962    | 
---------------------------------
Finished sucessfully.
MAP on training data: 0.8079
MAP on validation data: 0.8031
---------------------------------
MAP on test data: 0.7234

Model saved to: ../model/experiment/model_trigram.txt

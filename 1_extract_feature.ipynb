{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CoreNLP SETUP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download (https://stanfordnlp.github.io/CoreNLP/) and run Stanford CoreNLP server: \n",
    "```cd stanford-corenlp-full-2018-02-27```   \n",
    "```java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000```\n",
    "\n",
    "#### Optionally, if you want to load all \"annotators\":\n",
    "```java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -preload tokenize,ssplit,pos,lemma,ner,parse,depparse -timeout 15000```\n",
    "\n",
    "#### If successful, you will see:\n",
    "```[main] INFO CoreNLP - StanfordCoreNLPServer listening at /0:0:0:0:0:0:0:0:9000```\n",
    "\n",
    "#### To stop the server:  \n",
    "#### https://stanfordnlp.github.io/CoreNLP/corenlp-server.html#stopping-the-server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os               # os.path.join\n",
    "import pandas as pd\n",
    "\n",
    "import nltk             #for POS tagging\n",
    "from nltk.tree import *\n",
    "\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "parser = StanfordCoreNLP('http://localhost:9000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATA PATHS (DOCUMENTS and QUERIES)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/\"\n",
    "\n",
    "DATA_DOC = os.path.join(DATA_DIR, \"data_doc.csv\")\n",
    "DATA_QUERY_TRAIN = os.path.join(DATA_DIR, \"data_query_train.csv\")\n",
    "DATA_QUERY_VALIDATE_TEST = os.path.join(DATA_DIR, \"data_query_validate_test.csv\")\n",
    "\n",
    "FEATURE_DOC = os.path.join(DATA_DIR, \"feature_doc.csv\")\n",
    "FEATURE_QUERY_TRAIN = os.path.join(DATA_DIR, \"feature_query_train.csv\")\n",
    "FEATURE_QUERY_VALIDATE_TEST = os.path.join(DATA_DIR, \"feature_query_validate_test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HELPER FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_df(filepath):\n",
    "    \"\"\"\n",
    "    argument: csv file path to read from\n",
    "    return: pandas dataframe\n",
    "    \"\"\"\n",
    "    df1 = pd.read_csv(filepath)\n",
    "    return df1\n",
    "\n",
    "def df_to_csv(df, filepath):\n",
    "    \"\"\"\n",
    "    arguments: pandas dataframe, csv file path to write to\n",
    "    return: csv file\n",
    "    \"\"\"\n",
    "    df.to_csv(filepath, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_tuple_to_string(x):\n",
    "    \"\"\"\n",
    "    argument: list or tuple of words\n",
    "    return: string of words, separated by whitespace\n",
    "    \"\"\"\n",
    "    s = ''\n",
    "    for w in x:\n",
    "        if s == '':\n",
    "            s = w\n",
    "        else:\n",
    "            s = s + ' ' + w\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_string_with_underscore(s):\n",
    "    \"\"\"\n",
    "    argument: string of words separated by whitespace\n",
    "    return: words concatenated with the underscore character\n",
    "    \"\"\"\n",
    "    t = s.split()\n",
    "    s1 = ''\n",
    "    for w in t:\n",
    "        if s1 == '':\n",
    "            s1 = w\n",
    "        else:\n",
    "            s1 = s1 + '_' + w\n",
    "    return s1        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PARSE TREE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tree(s):\n",
    "    \"\"\"\n",
    "    argument: string\n",
    "    return: parse tree from Tree.fromstring()\n",
    "    \"\"\"\n",
    "    output = parser.annotate( s, properties={'annotators': 'parse', 'outputFormat': 'json', 'timeout': 1000,} )\n",
    "    if s:\n",
    "        t = output['sentences'][0]['parse']\n",
    "    else:\n",
    "        t = ''\n",
    "    if t:\n",
    "        return Tree.fromstring(t)\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tree_productions(s):\n",
    "    \"\"\"\n",
    "    arguments: question, answer (strings)\n",
    "    return: a string of all productions (excluding the root and leaf nodes) in constituency parse tree of question, \n",
    "    POS tags in each production concatenated by underscore character\n",
    "    \"\"\"\n",
    "    t1 = parse_tree(s)\n",
    "    if t1:\n",
    "        t2 = t1.productions()\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "    t3 = []\n",
    "    productions = ''\n",
    "    \n",
    "    for x in t2:\n",
    "        if \"'\" in str(x) or \"ROOT\" in str(x):  # leave out productions with root and leaf nodes\n",
    "            continue\n",
    "        else:\n",
    "            t3.append(x)\n",
    "    \n",
    "    for p in t3:\n",
    "        p1 = str(p).replace(\" ->\", \"\")\n",
    "        p2 = p1.replace(\" \", \"_\")\n",
    "        if productions == '':\n",
    "            productions = p2\n",
    "        else:\n",
    "            productions = productions + ' ' + p2\n",
    "    return productions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PARSE TREE PRINTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parse_tree(s):\n",
    "    \"\"\"\n",
    "    arguments: s (string)\n",
    "    return: the constituency parse tree\n",
    "    \"\"\"\n",
    "    t = parse_tree(s)    \n",
    "    t.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parse_tree_with_answer(q,a):\n",
    "    \"\"\"\n",
    "    arguments: question, answer (strings)\n",
    "    return: the constituency parse tree\n",
    "    call: print_parse_tree()\n",
    "    \"\"\"\n",
    "    q = q.replace(\"*\", a)\n",
    "    return print_parse_tree(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **POS TAGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_pos_tags(s):\n",
    "    \"\"\"\n",
    "    argument: string\n",
    "    return: POS tags (string) separated by whitespace\n",
    "    \"\"\"\n",
    "    t = s.split()               \n",
    "    word_tag = nltk.pos_tag(t)  # word_tag = [('He', 'PRP'), ...] \n",
    "    \n",
    "    tags = ''\n",
    "    for p in word_tag:          \n",
    "        tag = p[1]              # tag = 'PRP'\n",
    "        if tags == '':\n",
    "            tags = tag\n",
    "        else:\n",
    "            tags = tags + ' ' + tag\n",
    "    return tags    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NGRAMS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_list_to_string(ngram_list):\n",
    "    \"\"\"\n",
    "    argument: list of bigrams or trigrams of words\n",
    "    return: string of bigrams or trigrams separated by whitespace\n",
    "    \"\"\"\n",
    "    s1 = ''\n",
    "    for tup in ngram_list:\n",
    "        s2 = convert_list_tuple_to_string(tup)\n",
    "        s3 = concat_string_with_underscore(s2)\n",
    "        if s1 == '':\n",
    "            s1 = s3\n",
    "        else:\n",
    "            s1 = s1 + ' ' + s3\n",
    "    return s1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_bigrams(s):\n",
    "    \"\"\"\n",
    "    argument: string of words\n",
    "    return: string of bigrams of words, words concatenated by the underscore in each bigram\n",
    "    \"\"\"\n",
    "    t = s.split()\n",
    "    bigram_list = list(nltk.ngrams(t,2))  # list of tuples [('xxx','yyy'),...]\n",
    "    return ngram_list_to_string(bigram_list)\n",
    "\n",
    "\n",
    "def string_to_trigrams(s):\n",
    "    \"\"\"\n",
    "    argument: string of words\n",
    "    return: string of trigrams of words, words concatenated by the underscore in each trigram\n",
    "    \"\"\"\n",
    "    t = s.split()\n",
    "    trigram_list = list(nltk.ngrams(t,3))  # list of tuples [('xxx','yyy','zzz'),...]\n",
    "    return ngram_list_to_string(trigram_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **FIELD: SENTENCE (Model 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_complete(q,a):\n",
    "    \"\"\"\n",
    "    argument: question containing *, answer (strings)\n",
    "    return: the complete question in which * is replaced by the answer\n",
    "    \"\"\"\n",
    "    return q.replace(\"*\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **FIELD: WORDS BEFORE AND AFTER ANSWER (Model 2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_words_before_answer(q,n):\n",
    "    \"\"\"\n",
    "    argument: question (string) containing the * character\n",
    "    return: previous_word(string)\n",
    "        Two words to the left of the * character.\n",
    "        If * is the second word in the sentence, return one word.\n",
    "        If * is the first word in the sentence, return empty string.\n",
    "    \"\"\"\n",
    "    string_before = q.split('*')[0]                # split into two strings\n",
    "    word_list = string_before.strip().split(' ')[-n:]\n",
    "    return convert_list_tuple_to_string(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVE THIS CODE\n",
    "\n",
    "def n_words_after_answer(q,n):\n",
    "    \"\"\"\n",
    "    argument: question (string) containing the * character\n",
    "    return: next_word(string)\n",
    "        Two words to the right of the * character.\n",
    "        If * is the second last word, return the last word, excluding punctuation.\n",
    "        If * is the last word, return empty string.\n",
    "    \"\"\"\n",
    "    if q.endswith('*') or q == '':\n",
    "        return ''\n",
    "    else:\n",
    "        string_after = q.split('*')[1]               # split into two strings\n",
    "    word_list = string_after.strip().split(' ')[0:n]\n",
    "    w = convert_list_tuple_to_string(word_list)\n",
    "    if len(w) != 0:\n",
    "        last_char = w[len(w)-1]\n",
    "    if last_char == '.' or last_char == '?' or last_char == '!' or last_char == ',' or last_char == ';':\n",
    "        words = w[:-1]\n",
    "    else:    \n",
    "        words = w\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **FIELD: SUBSTRING (Model 2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_substring(q,a,n):\n",
    "    \"\"\"\n",
    "    argument: question containing *, answer (strings), integer n (number of words before and after answer)\n",
    "    return: the string 'ppp aaa xxx', \n",
    "        where \n",
    "        ppp are the n words before the answer\n",
    "        aaa is the answer\n",
    "        xxx are the n words after the answer\n",
    "    \"\"\"\n",
    "    s1 = n_words_before_answer(q,n)\n",
    "    s2 = n_words_after_answer(q,n)\n",
    "    return (s1 + ' ' + a + ' ' + s2).strip()    # remove any white space at the start and end of string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **FIELD: WORDS BEFORE ANSWER (Model 2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_word_of_string(s):\n",
    "    \"\"\"\n",
    "    argument: string\n",
    "    returns: last word in the string\n",
    "    \"\"\"\n",
    "    if s:\n",
    "        s1 = s.split()\n",
    "        return s1[-1]\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **FIELD: WORDS AFTER ANSWER (Model 2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_word_of_string(s):\n",
    "    \"\"\"\n",
    "    argument: string\n",
    "    returns: first word in the string\n",
    "    \"\"\"\n",
    "    if s:\n",
    "        s1 = s.split()\n",
    "        return s1[0]\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **FIELD: ANSWER (Model 2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_is_at_beginning_doc(q):\n",
    "    \"\"\"\n",
    "    argument: question (string) containing the * character\n",
    "    return: boolean \n",
    "        1 if * is at the start of the question\n",
    "        0 otherwise\n",
    "    \"\"\"\n",
    "    t = q.split(' ',1)[0]        \n",
    "    if t == '*':\n",
    "        return 'b'\n",
    "    else:\n",
    "        return 'x'\n",
    "\n",
    "def answer_is_at_end_doc(q):\n",
    "    \"\"\"\n",
    "    argument: question(string) containing the * character\n",
    "    return: boolean \n",
    "        1 if * is at the end of the question\n",
    "        0 otherwise\n",
    "    \"\"\"\n",
    "    t = q.split('*')[1]              \n",
    "    if t == '.' or t == '?' or t == '!':\n",
    "        return 'e'\n",
    "    else:\n",
    "        return 'x' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_is_at_beginning_query(q):\n",
    "    \"\"\"\n",
    "    argument: question (string) containing the * character\n",
    "    return: boolean \n",
    "        1 if * is at the start of the question\n",
    "        0 otherwise\n",
    "    \"\"\"\n",
    "    t = q.split(' ',1)[0]        \n",
    "    if t == '*':\n",
    "        return 'b'\n",
    "    else:\n",
    "        return 'y'\n",
    "    \n",
    "def answer_is_at_end_query(q):\n",
    "    \"\"\"\n",
    "    argument: question(string) containing the * character\n",
    "    return: boolean \n",
    "        1 if * is at the end of the question\n",
    "        0 otherwise\n",
    "    \"\"\"\n",
    "    t = q.split('*')[1]              \n",
    "    if t == '.' or t == '?' or t == '!':\n",
    "        return 'e'\n",
    "    else:\n",
    "        return 'y'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_length(s):\n",
    "    \"\"\"\n",
    "    argument: sentence (string)\n",
    "    return: the number of words in the sentence (integer)\n",
    "        * is counted as one word.\n",
    "    \"\"\"\n",
    "    return len(s.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CREATE FEATURE DATAFRAMES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 1 FEATURES\n",
    "\n",
    "def create_features_df_model1(df,doc):\n",
    "    \"\"\"\n",
    "    argument: pandas dataframe\n",
    "    return: pandas dataframe with features \n",
    "    \"\"\"    \n",
    "    for i, row in df.iterrows(): \n",
    "        q = row['qb_question']\n",
    "        a = row['qb_answer']\n",
    "        qa = question_complete(q,a)\n",
    "        qa_tags = words_to_pos_tags(qa)\n",
    "        \n",
    "        df.loc[i,'qa'] = qa             # for baseline BM25 ranking in Model 1       \n",
    "        df.loc[i,'qa_pos'] = qa_tags\n",
    "        df.loc[i,'qa_pos_bigram'] = string_to_bigrams(qa_tags) \n",
    "        df.loc[i,'qa_pos_trigram'] = string_to_trigrams(qa_tags)\n",
    "        df.loc[i,'qa_parse_tree'] = parse_tree_productions(qa)        \n",
    "        \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 2 FEATURES\n",
    "\n",
    "def create_features_df_model2(df, data_type):\n",
    "    \"\"\"\n",
    "    argument: pandas dataframe\n",
    "    return: pandas dataframe with features \n",
    "    \"\"\" \n",
    "    n = 4\n",
    "    for i, row in df.iterrows(): \n",
    "        q = row['qb_question']\n",
    "        a = row['qb_answer']\n",
    "        substr = question_substring(q,a,n)\n",
    "        substr_tags = words_to_pos_tags(substr)\n",
    "        \n",
    "        # FIELD: substring\n",
    "        df.loc[i,'ss'] = substr             # for baseline BM25 ranking in Model 2       \n",
    "        df.loc[i,'ss_pos'] = substr_tags\n",
    "        df.loc[i,'ss_pos_bigram'] = string_to_bigrams(substr_tags) \n",
    "        df.loc[i,'ss_pos_trigram'] = string_to_trigrams(substr_tags)\n",
    "        df.loc[i,'ss_parse_tree'] = parse_tree_productions(substr)        \n",
    "        \n",
    "        # FIELD: words before answer\n",
    "        before = n_words_before_answer(q,n)\n",
    "        before_tags = words_to_pos_tags(before)\n",
    "        last = last_word_of_string(before) \n",
    "        last_tag = words_to_pos_tags(last)\n",
    "\n",
    "        df.loc[i,'before'] = before \n",
    "        df.loc[i,'before_last'] = last\n",
    "        df.loc[i,'before_last_pos'] = last_tag\n",
    "        df.loc[i,'before_pos'] = before_tags\n",
    "        df.loc[i,'before_pos_bigram'] = string_to_bigrams(before_tags)\n",
    "        df.loc[i,'before_pos_trigram'] = string_to_trigrams(before_tags)\n",
    "        df.loc[i,'before_parse_tree'] = parse_tree_productions(before)\n",
    "        \n",
    "        # FIELD: words after answer\n",
    "        after = n_words_after_answer(q,n)\n",
    "        after_tags = words_to_pos_tags(after)\n",
    "        first = first_word_of_string(after) \n",
    "        first_tag = words_to_pos_tags(first)\n",
    "\n",
    "        df.loc[i,'after'] = after \n",
    "        df.loc[i,'after_first'] = first\n",
    "        df.loc[i,'after_first_pos'] = first_tag\n",
    "        df.loc[i,'after_pos'] = after_tags\n",
    "        df.loc[i,'after_pos_bigram'] = string_to_bigrams(after_tags)\n",
    "        df.loc[i,'after_pos_trigram'] = string_to_trigrams(after_tags)\n",
    "        df.loc[i,'after_parse_tree'] = parse_tree_productions(after)\n",
    "        \n",
    "        # FIELD: answer        \n",
    "        ans_tags = words_to_pos_tags(a)\n",
    "        ans_first = first_word_of_string(a) \n",
    "        ans_last = last_word_of_string(a)\n",
    "\n",
    "        df.loc[i,'ans'] = a\n",
    "        df.loc[i,'ans_first'] = ans_first\n",
    "        df.loc[i,'ans_last'] = ans_last\n",
    "        df.loc[i,'ans_pos'] = concat_string_with_underscore(ans_tags)\n",
    "        df.loc[i,'ans_first_pos'] = words_to_pos_tags(ans_first) \n",
    "        df.loc[i,'ans_last_pos'] = words_to_pos_tags(ans_last) \n",
    "        \n",
    "        if data_type == 'doc':\n",
    "            df.loc[i,'ans_is_first'] = answer_is_at_beginning_doc(q) \n",
    "            df.loc[i,'ans_is_last'] = answer_is_at_end_doc(q) \n",
    "        elif data_type == 'query':\n",
    "            df.loc[i,'ans_is_first'] = answer_is_at_beginning_query(q)\n",
    "            df.loc[i,'ans_is_last'] = answer_is_at_end_query(q)\n",
    "        df.loc[i,'ans_length'] = string_length(a) \n",
    "\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RUN!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CONVERT CSV DATA TO DATAFRAME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_doc = csv_to_df(DATA_DOC)\n",
    "\n",
    "df_data_query_train = csv_to_df(DATA_QUERY_TRAIN)\n",
    "df_data_query_validate_test = csv_to_df(DATA_QUERY_VALIDATE_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **EXTRACT FEATURES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOCUMENT FEATURES\n",
    "\n",
    "df_doc = create_features_df_model1(df_data_doc, 'doc')\n",
    "df_features_doc = create_features_df_model2(df_doc, 'doc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUERY FEATURES\n",
    "\n",
    "df_query1 = create_features_df_model1(df_data_query_train, 'query')\n",
    "df_features_query_train = create_features_df_model2(df_query1, 'query')\n",
    "\n",
    "df_query2 = create_features_df_model1(df_data_query_validate_test, 'query')\n",
    "df_features_query_validate_test = create_features_df_model2(df_query2, 'query')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CONVERT DATAFRAMES TO CSV FILES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_csv(df_features_doc, FEATURE_DOC)\n",
    "\n",
    "df_to_csv(df_features_query_train, FEATURE_QUERY_TRAIN)\n",
    "df_to_csv(df_features_query_validate_test, FEATURE_QUERY_VALIDATE_TEST)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

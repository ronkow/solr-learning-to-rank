{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os        \n",
    "import json      \n",
    "import xml.etree.ElementTree as ET   # ET.parse\n",
    "import solr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATA PATHS, GLOBAL VARIABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR  = \"model/\"\n",
    "\n",
    "MODEL1_TXT = os.path.join(MODEL_DIR, \"final/model1.txt\")\n",
    "MODEL1_XML = os.path.join(MODEL_DIR, \"final/model1.xml\")\n",
    "MODEL1_JSON = os.path.join(MODEL_DIR, \"final/model1.json\")\n",
    "\n",
    "MODEL2_TXT = os.path.join(MODEL_DIR, \"final/model2.txt\")\n",
    "MODEL2_XML = os.path.join(MODEL_DIR, \"final/model2.xml\")\n",
    "MODEL2_JSON = os.path.join(MODEL_DIR, \"final/model2.json\")\n",
    "\n",
    "BASELINE_MODEL1_TXT = os.path.join(MODEL_DIR, \"baseline/baseline_model1.txt\")\n",
    "BASELINE_MODEL1_XML = os.path.join(MODEL_DIR, \"baseline/baseline_model1.xml\")\n",
    "BASELINE_MODEL1_JSON = os.path.join(MODEL_DIR, \"baseline/baseline_model1.json\")\n",
    "\n",
    "BASELINE_MODEL2_TXT = os.path.join(MODEL_DIR, \"baseline/baseline_model2.txt\")\n",
    "BASELINE_MODEL2_XML = os.path.join(MODEL_DIR, \"baseline/baseline_model2.xml\")\n",
    "BASELINE_MODEL2_JSON = os.path.join(MODEL_DIR, \"baseline/baseline_model2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TRAIN LTR MODELS USING RANKLIB (RUN JAVA in TERMINAL)**\n",
    "#### https://sourceforge.net/p/lemur/wiki/RankLib/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TO TRAIN MODEL:\n",
    "\n",
    "```cd ranklib_directory``` \n",
    "\n",
    "    \n",
    "```java -jar RankLib-2.14.jar``` \n",
    "    ```-train ../path/train.txt``` \n",
    "    ```-test ../path/test.txt``` \n",
    "    ```-validate ../path/validate.txt``` \n",
    "    ```-ranker 6``` \n",
    "    ```-metric2t NDCG@10```\n",
    "    ```-metric2T NDCG@10``` \n",
    "    ```-save ../model/model.txt```   \n",
    "    \n",
    "#### NOTES ON PARAMS:\n",
    "```-ranker 6```  refers to LambdaMART  \n",
    "```-metric2t <metric>```  refers to Metric to optimize on the training data. Supported: MAP, NDCG@k, DCG@k, P@k, RR@k, ERR@k (default=ERR@10)      \n",
    "```-metric2T <metric>```  refers to Metric to evaluate on the test data (default to the same as specified for -metric2t)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CONVERT TXT FILE TO XML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_to_xml(FILE_TXT, FILE_XML):\n",
    "    \"\"\"\n",
    "    Convert the tree model (txt format) to xml format\n",
    "    Parameters:\n",
    "        FILE_TXT: path of text file to be read\n",
    "        FILE_XML: path of xml file to write to\n",
    "    \"\"\"\n",
    "    ftxt = open(FILE_TXT, \"r\")\n",
    "    fxml = open(FILE_XML, \"w\")\n",
    "    \n",
    "    fxml.write(\"<?xml version=\\\"1.0\\\"?>\\n\")\n",
    "    for line in ftxt:\n",
    "        if line.startswith(\"##\") or len(line.strip()) == 0:\n",
    "            continue\n",
    "        fxml.write(\"{:s}\".format(line))\n",
    "    fxml.close()\n",
    "    ftxt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **CONVERT MODEL XML FILE TO JSON**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_split(el_split, feature_id2name, split_type=\"root\"):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        el_split\n",
    "        feature_id2name: id and name of feature \n",
    "        split_type: \"root\"\n",
    "    Return: Tree node definition in JSON format\n",
    "    \"\"\"\n",
    "    if split_type != \"root\":\n",
    "        split_type = el_split.attrib[\"pos\"]\n",
    "    output = el_split.find(\"output\")\n",
    "    \n",
    "    if output is not None:\n",
    "        return {\n",
    "            \"value\": output.text.strip()\n",
    "        }\n",
    "    \n",
    "    feature = feature_id2name[int(el_split.find(\"feature\").text.strip())]\n",
    "    threshold = el_split.find(\"threshold\").text.strip()\n",
    "    el_csplits = el_split.findall(\"split\")\n",
    "    \n",
    "    for el_csplit in el_csplits:\n",
    "        attr_pos = el_csplit.attrib[\"pos\"]\n",
    "        if attr_pos == \"left\":\n",
    "            left = parse_split(el_csplit, feature_id2name, \"left\")\n",
    "        elif attr_pos == \"right\":\n",
    "            right = parse_split(el_csplit, feature_id2name, \"right\")\n",
    "    return {\n",
    "        \"feature\": feature,\n",
    "        \"threshold\": threshold,\n",
    "        \"left\": left,\n",
    "        \"right\": right\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_json(FILE_XML, FILE_JSON, FEATURE_LIST, feature_store, model_name):\n",
    "    \"\"\"\n",
    "    Convert the tree model (xml format) to JSON format\n",
    "    Parameters:\n",
    "        FILE_XML: tree model in XML format\n",
    "        FILE_JSON: tree model in JSON format\n",
    "        FEATURE_LIST: list of feature names\n",
    "        feature_store: name of feature store\n",
    "        model_name: name of model store\n",
    "    Calls:\n",
    "        parse_split(el_split, feature_id2name)\n",
    "    \"\"\"\n",
    "    trees = []\n",
    "    feature_id2name = {i+1:f for i, f in enumerate(FEATURE_LIST)}\n",
    "    xml = ET.parse(FILE_XML)\n",
    "    el_ensemble = xml.getroot()\n",
    "    \n",
    "    for el_tree in el_ensemble:\n",
    "        weight = el_tree.attrib[\"weight\"]\n",
    "        el_split = el_tree.find(\"split\")\n",
    "        tree_dict = {\n",
    "            \"weight\": weight,\n",
    "            \"root\": parse_split(el_split, feature_id2name)\n",
    "        }\n",
    "        trees.append(tree_dict)\n",
    "    \n",
    "    params_dict = {\"trees\" : trees}\n",
    "    \n",
    "    features = [{\"name\": f} for f in FEATURE_LIST]\n",
    "\n",
    "    model_dict = {\n",
    "        \"store\": feature_store,\n",
    "        \"name\": model_name,\n",
    "        \"class\": \"org.apache.solr.ltr.model.MultipleAdditiveTreesModel\",\n",
    "        \"features\": features,\n",
    "        \"params\": params_dict\n",
    "    }\n",
    "\n",
    "    with open(FILE_JSON, \"w\") as fjson:\n",
    "        fjson.write(json.dumps(model_dict, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RUN!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_to_xml(MODEL1_TXT, MODEL1_XML)\n",
    "txt_to_xml(MODEL2_TXT, MODEL2_XML)\n",
    "\n",
    "txt_to_xml(MODEL1_TXT, MODEL1_XML)\n",
    "txt_to_xml(MODEL2_TXT, MODEL2_XML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_to_xml(BASELINE_MODEL1_TXT, BASELINE_MODEL1_XML)\n",
    "txt_to_xml(BASELINE_MODEL2_TXT, BASELINE_MODEL2_XML)\n",
    "\n",
    "txt_to_xml(BASELINE_MODEL1_TXT, BASELINE_MODEL1_XML)\n",
    "txt_to_xml(BASELINE_MODEL2_TXT, BASELINE_MODEL2_XML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_LIST_ONE = solr.feature_list(1)\n",
    "FL2 = solr.feature_list(2)\n",
    "\n",
    "FEATURE_LIST_TWO = FL2[:-1]   # remove topic_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_LIST_ONE_BASELINE = solr.feature_list(3)\n",
    "FEATURE_LIST_TWO_BASELINE = solr.feature_list(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_to_json(MODEL1_XML, MODEL1_JSON, FEATURE_LIST_ONE, 'feature_store1', 'lambdamart_model1')\n",
    "xml_to_json(MODEL2_XML, MODEL2_JSON, FEATURE_LIST_TWO, 'feature_store2', 'lambdamart_model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_to_json(BASELINE_MODEL1_XML, BASELINE_MODEL1_JSON, FEATURE_LIST_ONE_BASELINE, 'feature_store1', 'lambdamart_model1_baseline')\n",
    "xml_to_json(BASELINE_MODEL2_XML, BASELINE_MODEL2_JSON, FEATURE_LIST_TWO_BASELINE, 'feature_store2', 'lambdamart_model2_baseline')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

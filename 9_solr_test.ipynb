{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random    \n",
    "import os        \n",
    "import csv       \n",
    "import json      \n",
    "import requests  \n",
    "import urllib    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DATA PATHS, GLOBAL VARIABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR  = \"data/\"\n",
    "FEATURE_QUERY_VALIDATE_TEST = os.path.join(DATA_DIR, \"feature_query_validate_test.csv\")\n",
    "\n",
    "SOLR_URL = \"http://localhost:8983/solr/core1\"\n",
    "\n",
    "N = 10    # Top N results to display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **GET A RANDOM QUERY FROM THE VALIDATION_TEST DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_query(myseed):\n",
    "\n",
    "    with open(FEATURE_QUERY_VALIDATE_TEST) as f:\n",
    "        QUERY_LIST = [ {k: v for k, v in row.items()} for row in csv.DictReader(f, skipinitialspace=True) ]\n",
    "    \n",
    "    random.seed(myseed)\n",
    "    random.shuffle(QUERY_LIST)\n",
    "       \n",
    "    query = QUERY_LIST[0]  \n",
    "    return query   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HELPER FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_results(docs, query, ans, topic, top_n):\n",
    "\n",
    "    print(f\"Top {top_n} results for the query: {query} (answer: {ans}, topic: {topic})\\n\")\n",
    "    \n",
    "    for doc in docs:\n",
    "        doc_id = int(doc[\"id\"])\n",
    "        qb_question = doc[\"qb_question\"][0]                   # solr indexed the data as a list! Can this be fixed?\n",
    "        qb_answer = doc[\"qb_answer\"][0]\n",
    "        qb_topic_id = doc[\"qb_topic_id\"][0]\n",
    "        print(f\"doc_id: {doc_id} \\t {qb_question} ({qb_answer})(topic: {qb_topic_id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_solr(payload):\n",
    "    \n",
    "    params = urllib.parse.urlencode(payload, quote_via=urllib.parse.quote_plus)\n",
    "    search_url = SOLR_URL + \"/query?\" + params\n",
    "    resp = requests.get(search_url)\n",
    "    resp_json = json.loads(resp.text)\n",
    "    docs = resp_json[\"response\"][\"docs\"]\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PAYLOAD TO QUERY SOLR BY DEFAULT BM25 (ENTIRE SENTENCE or SUBSTRING)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODEL: Default Solr (entire sentence)\n",
    "\n",
    "def run_query_default_qa(q):\n",
    "       \n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "    \n",
    "    query = q['qa']\n",
    "    \n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"qa\",\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N\n",
    "    }\n",
    "\n",
    "    docs = query_solr(payload)\n",
    "    print(\"Default Solr results (query: entire sentence):\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO MODEL: Default Solr (substring)\n",
    "\n",
    "def run_query_default_ss(q):\n",
    "       \n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "    \n",
    "    query = q['ss']\n",
    "    \n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"ss\",\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N\n",
    "    }\n",
    "\n",
    "    docs = query_solr(payload)\n",
    "    print(\"Default Solr results (query: substring):\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PAYLOAD TO QUERY SOLR USING LAMBDAMART BASELINE MODELS**\n",
    "#### Baseline models only have one feature: BM25 for entire sentence (Model 1) or BM25 for substring (Model 2)\n",
    "\n",
    "#### When we enable LTR, Solr will rerank the original results from default BM25 (i.e when no LTR models are used)\n",
    "#### By default, Solr reranks the top 200 results.\n",
    "#### But we can set the number N of reranks by setting the `reRankDocs` parameter, for example, to rerank only the top 10 results:\n",
    "`\"rq\": f'{{!ltr model=lambdamart_model1 reRankDocs=10 ...}}',`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LTR BASELINE MODEL 1 (entire sentence)\n",
    "\n",
    "def run_query_lambdamart_baseline_model1(q):\n",
    "    \n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "\n",
    "    query = q['qa']\n",
    "\n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"qa\",\n",
    "        \"rq\": f'{{!ltr model=lambdamart_model1_baseline}}',\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N\n",
    "    }\n",
    "\n",
    "    docs = query_solr(payload)\n",
    "    print(\"LTR Baseline Model 1 results:\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LTR BASELINE MODEL 2 (substring)\n",
    "\n",
    "def run_query_lambdamart_baseline_model2(q):\n",
    "    \n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "\n",
    "    query = q['ss']\n",
    "\n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"ss\",\n",
    "        \"rq\": f'{{!ltr model=lambdamart_model2_baseline}}',\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N\n",
    "    }\n",
    "\n",
    "    docs = query_solr(payload)\n",
    "    print(\"LTR Baseline Model 2 results:\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PAYLOAD TO QUERY SOLR USING LAMBDAMART MODELS 1 AND 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LTR MODEL 1\n",
    "\n",
    "def run_query_lambdamart_model1(q):\n",
    "\n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "\n",
    "    query = q['qa']\n",
    "    f2 = q[\"qa_pos\"]\n",
    "    f3 = q[\"qa_pos_bigram\"]\n",
    "    f4 = q[\"qa_pos_trigram\"]\n",
    "    f5 = q[\"qa_parse_tree\"]\n",
    "    \n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"qa\",\n",
    "        \"rq\": f'{{!ltr model=lambdamart_model1 \\\n",
    "        efi.q2=\"{f2}\" \\\n",
    "        efi.q3=\"{f3}\" \\\n",
    "        efi.q4=\"{f4}\" \\\n",
    "        efi.q5=\"{f5}\"}}',\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N\n",
    "    }\n",
    "\n",
    "    docs = query_solr(payload)\n",
    "    print(\"LTR Model 1 results:\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with LTR MODEL 2\n",
    "\n",
    "def run_query_lambdamart_model2(q):\n",
    "    \n",
    "    ans = q['qb_answer']\n",
    "    topic = q['qb_topic_id']\n",
    "\n",
    "    query = q['ss']\n",
    "    f2 = q[\"ss_pos\"]\n",
    "    f3 = q[\"ss_pos_bigram\"]\n",
    "    f4 = q[\"ss_pos_trigram\"]\n",
    "    f5 = q[\"ss_parse_tree\"]\n",
    "    f6 = q[\"before\"]\n",
    "    f7 = q[\"before_last\"]\n",
    "    f8 = (q[\"before_last_pos\"]).lower()\n",
    "    f9 = q[\"before_pos\"]\n",
    "    f10 = q[\"before_pos_bigram\"]\n",
    "    f11 = q[\"before_pos_trigram\"]\n",
    "    f12 = q[\"before_parse_tree\"]\n",
    "    f13 = q[\"after\"]\n",
    "    f14 = q[\"after_first\"]\n",
    "    f15 = (q[\"after_first_pos\"]).lower()\n",
    "    f16 = q[\"after_pos\"]\n",
    "    f17 = q[\"after_pos_bigram\"]\n",
    "    f18 = q[\"after_pos_trigram\"]\n",
    "    f19 = q[\"after_parse_tree\"]\n",
    "    f20 = q[\"ans\"]\n",
    "    f21 = q[\"ans_first\"]\n",
    "    f22 = q[\"ans_last\"]\n",
    "    f23 = (q[\"ans_pos\"]).lower()\n",
    "    f24 = (q[\"ans_first_pos\"]).lower()\n",
    "    f25 = (q[\"ans_last_pos\"]).lower()\n",
    "    f26 = q[\"ans_is_first\"]\n",
    "    f27 = q[\"ans_is_last\"]\n",
    "    f28 = q[\"ans_length\"]\n",
    "    \n",
    "    payload = {\n",
    "        \"q\": query,\n",
    "        \"defType\": \"edismax\",\n",
    "        \"qf\": \"ss\",\n",
    "        \"rq\": f'{{!ltr model=lambdamart_model2 \\\n",
    "        efi.q2=\"{f2}\" \\\n",
    "        efi.q3=\"{f3}\" \\\n",
    "        efi.q4=\"{f4}\" \\\n",
    "        efi.q5=\"{f5}\" \\\n",
    "        efi.q6=\"{f6}\" \\\n",
    "        efi.q7=\"{f7}\" \\\n",
    "        efi.q8=\"{f8}\" \\\n",
    "        efi.q9=\"{f9}\" \\\n",
    "        efi.q10=\"{f10}\" \\\n",
    "        efi.q11=\"{f11}\" \\\n",
    "        efi.q12=\"{f12}\" \\\n",
    "        efi.q13=\"{f13}\" \\\n",
    "        efi.q14=\"{f14}\" \\\n",
    "        efi.q15=\"{f15}\" \\\n",
    "        efi.q16=\"{f16}\" \\\n",
    "        efi.q17=\"{f17}\" \\\n",
    "        efi.q18=\"{f18}\" \\\n",
    "        efi.q19=\"{f19}\" \\\n",
    "        efi.q20=\"{f20}\" \\\n",
    "        efi.q21=\"{f21}\" \\\n",
    "        efi.q22=\"{f22}\" \\\n",
    "        efi.q23=\"{f23}\" \\\n",
    "        efi.q24=\"{f24}\" \\\n",
    "        efi.q25=\"{f25}\" \\\n",
    "        efi.q26=\"{f26}\" \\\n",
    "        efi.q27=\"{f27}\" \\\n",
    "        efi.q28=\"{f28}\"}}',\n",
    "        \"fl\": \"id, qb_question, qb_answer, qb_topic_id\",            \n",
    "        \"rows\": N,\n",
    "    }\n",
    "    \n",
    "    docs = query_solr(payload)\n",
    "    print(\"LTR Model 1 results:\")\n",
    "    return render_results(docs, query, ans, topic, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TESTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '9120',\n",
       " 'qb_question': 'She was going for play and asked him if he wants to *.',\n",
       " 'qb_answer': 'come along',\n",
       " 'qb_topic_id': '3',\n",
       " 'qa': 'She was going for play and asked him if he wants to come along.',\n",
       " 'qa_pos': 'PRP VBD VBG IN NN CC VBD PRP IN PRP VBZ TO VB NN',\n",
       " 'qa_pos_bigram': 'PRP_VBD VBD_VBG VBG_IN IN_NN NN_CC CC_VBD VBD_PRP PRP_IN IN_PRP PRP_VBZ VBZ_TO TO_VB VB_NN',\n",
       " 'qa_pos_trigram': 'PRP_VBD_VBG VBD_VBG_IN VBG_IN_NN IN_NN_CC NN_CC_VBD CC_VBD_PRP VBD_PRP_IN PRP_IN_PRP IN_PRP_VBZ PRP_VBZ_TO VBZ_TO_VB TO_VB_NN',\n",
       " 'qa_parse_tree': 'S_NP_VP_. NP_PRP VP_VP_CC_VP VP_VBD_VP VP_VBG_PP PP_IN_NP NP_NN VP_VBD_NP_SBAR NP_PRP SBAR_IN_S S_NP_VP NP_PRP VP_VBZ_S S_VP VP_TO_VP VP_VB_ADVP ADVP_RB',\n",
       " 'ss': 'if he wants to come along',\n",
       " 'ss_pos': 'IN PRP VBZ TO VB IN',\n",
       " 'ss_pos_bigram': 'IN_PRP PRP_VBZ VBZ_TO TO_VB VB_IN',\n",
       " 'ss_pos_trigram': 'IN_PRP_VBZ PRP_VBZ_TO VBZ_TO_VB TO_VB_IN',\n",
       " 'ss_parse_tree': 'SBAR_IN_S S_NP_VP NP_PRP VP_VBZ_S S_VP VP_TO_VP VP_VB_ADVP ADVP_RB',\n",
       " 'before': 'if he wants to',\n",
       " 'before_last': 'to',\n",
       " 'before_last_pos': 'TO',\n",
       " 'before_pos': 'IN PRP VBZ TO',\n",
       " 'before_pos_bigram': 'IN_PRP PRP_VBZ VBZ_TO',\n",
       " 'before_pos_trigram': 'IN_PRP_VBZ PRP_VBZ_TO',\n",
       " 'before_parse_tree': 'SBAR_IN_S S_NP_VP NP_PRP VP_VBZ_S S_VP VP_TO',\n",
       " 'after': '',\n",
       " 'after_first': '',\n",
       " 'after_first_pos': '',\n",
       " 'after_pos': '',\n",
       " 'after_pos_bigram': '',\n",
       " 'after_pos_trigram': '',\n",
       " 'after_parse_tree': '',\n",
       " 'ans': 'come along',\n",
       " 'ans_first': 'come',\n",
       " 'ans_last': 'along',\n",
       " 'ans_pos': 'VBN_IN',\n",
       " 'ans_first_pos': 'VB',\n",
       " 'ans_last_pos': 'IN',\n",
       " 'ans_is_first': 'y',\n",
       " 'ans_is_last': 'e',\n",
       " 'ans_length': '2.0'}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_random_query(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Solr results (query: entire sentence):\n",
      "Top 10 results for the query: She was going for play and asked him if he wants to come along. (answer: come along, topic: 3)\n",
      "\n",
      "doc_id: 350 \t Please * if you want to audition for the part. (come along)(topic: 3)\n",
      "doc_id: 369 \t She * to me and asked for directions. (came up)(topic: 3)\n",
      "doc_id: 348 \t We are going to the movies. Do you want to *? (come along)(topic: 3)\n",
      "doc_id: 347 \t I waited for an hour and then four buses * at once. (come along)(topic: 3)\n",
      "doc_id: 175 \t She stayed up and waited for him till * midnight. (after)(topic: 1)\n",
      "doc_id: 224 \t You cannot go for the mountain hike * I come along. (unless)(topic: 2)\n",
      "doc_id: 216 \t She asked me * I was interested to join the party. (whether)(topic: 2)\n",
      "doc_id: 349 \t You can * if you want but you must watch the proceedings in silence. (come along)(topic: 3)\n",
      "doc_id: 346 \t You cannot go to the party unless I *. (come along)(topic: 3)\n",
      "doc_id: 604 \t I * to the conclusion that he is a liar. Do not trust him. (have come)(topic: 4)\n",
      "\n",
      "LTR Baseline Model 1 results:\n",
      "Top 10 results for the query: She was going for play and asked him if he wants to come along. (answer: come along, topic: 3)\n",
      "\n",
      "doc_id: 350 \t Please * if you want to audition for the part. (come along)(topic: 3)\n",
      "doc_id: 347 \t I waited for an hour and then four buses * at once. (come along)(topic: 3)\n",
      "doc_id: 348 \t We are going to the movies. Do you want to *? (come along)(topic: 3)\n",
      "doc_id: 369 \t She * to me and asked for directions. (came up)(topic: 3)\n",
      "doc_id: 224 \t You cannot go for the mountain hike * I come along. (unless)(topic: 2)\n",
      "doc_id: 349 \t You can * if you want but you must watch the proceedings in silence. (come along)(topic: 3)\n",
      "doc_id: 346 \t You cannot go to the party unless I *. (come along)(topic: 3)\n",
      "doc_id: 175 \t She stayed up and waited for him till * midnight. (after)(topic: 1)\n",
      "doc_id: 216 \t She asked me * I was interested to join the party. (whether)(topic: 2)\n",
      "doc_id: 420 \t I was asked to * the report before sending it for approval. (look over)(topic: 3)\n",
      "\n",
      "LTR Model 1 results:\n",
      "Top 10 results for the query: She was going for play and asked him if he wants to come along. (answer: come along, topic: 3)\n",
      "\n",
      "doc_id: 294 \t I would have helped you * you had asked me. (if)(topic: 2)\n",
      "doc_id: 665 \t He told me that he * for five years. (had been unemployed)(topic: 4)\n",
      "doc_id: 741 \t I would have helped you if you had asked *. (me)(topic: 5)\n",
      "doc_id: 259 \t You can come to me * you need help. (whenever)(topic: 2)\n",
      "doc_id: 348 \t We are going to the movies. Do you want to *? (come along)(topic: 3)\n",
      "doc_id: 86 \t She sat * the grass and looked up at the sky. (on)(topic: 1)\n",
      "doc_id: 183 \t He tends to feel uneasy when he is * strangers. (among)(topic: 1)\n",
      "doc_id: 239 \t She bought some flowers * she was shopping for groceries. (while)(topic: 2)\n",
      "doc_id: 309 \t He was so happy he * a song and declared his love for her. (broke into)(topic: 3)\n",
      "doc_id: 310 \t She * a song and entertained the guests. (broke into)(topic: 3)\n",
      "\n",
      "Default Solr results (query: substring):\n",
      "Top 10 results for the query: if he wants to come along (answer: come along, topic: 3)\n",
      "\n",
      "doc_id: 350 \t Please * if you want to audition for the part. (come along)(topic: 3)\n",
      "doc_id: 349 \t You can * if you want but you must watch the proceedings in silence. (come along)(topic: 3)\n",
      "doc_id: 348 \t We are going to the movies. Do you want to *? (come along)(topic: 3)\n",
      "doc_id: 346 \t You cannot go to the party unless I *. (come along)(topic: 3)\n",
      "doc_id: 224 \t You cannot go for the mountain hike * I come along. (unless)(topic: 2)\n",
      "doc_id: 347 \t I waited for an hour and then four buses * at once. (come along)(topic: 3)\n",
      "doc_id: 16 \t I have come * the conclusion that he is a liar. (to)(topic: 1)\n",
      "doc_id: 152 \t He drove * the tunnel along the highway. (through)(topic: 1)\n",
      "doc_id: 296 \t * he had brought a map he would not have got lost. (If)(topic: 2)\n",
      "doc_id: 427 \t He could not * with his in-laws. (get along)(topic: 3)\n",
      "\n",
      "LTR Baseline Model 2 results:\n",
      "Top 10 results for the query: if he wants to come along (answer: come along, topic: 3)\n",
      "\n",
      "doc_id: 350 \t Please * if you want to audition for the part. (come along)(topic: 3)\n",
      "doc_id: 348 \t We are going to the movies. Do you want to *? (come along)(topic: 3)\n",
      "doc_id: 349 \t You can * if you want but you must watch the proceedings in silence. (come along)(topic: 3)\n",
      "doc_id: 346 \t You cannot go to the party unless I *. (come along)(topic: 3)\n",
      "doc_id: 16 \t I have come * the conclusion that he is a liar. (to)(topic: 1)\n",
      "doc_id: 224 \t You cannot go for the mountain hike * I come along. (unless)(topic: 2)\n",
      "doc_id: 347 \t I waited for an hour and then four buses * at once. (come along)(topic: 3)\n",
      "doc_id: 152 \t He drove * the tunnel along the highway. (through)(topic: 1)\n",
      "doc_id: 604 \t I * to the conclusion that he is a liar. Do not trust him. (have come)(topic: 4)\n",
      "doc_id: 427 \t He could not * with his in-laws. (get along)(topic: 3)\n",
      "\n",
      "LTR Model 1 results:\n",
      "Top 10 results for the query: if he wants to come along (answer: come along, topic: 3)\n",
      "\n",
      "doc_id: 348 \t We are going to the movies. Do you want to *? (come along)(topic: 3)\n",
      "doc_id: 349 \t You can * if you want but you must watch the proceedings in silence. (come along)(topic: 3)\n",
      "doc_id: 346 \t You cannot go to the party unless I *. (come along)(topic: 3)\n",
      "doc_id: 347 \t I waited for an hour and then four buses * at once. (come along)(topic: 3)\n",
      "doc_id: 350 \t Please * if you want to audition for the part. (come along)(topic: 3)\n",
      "doc_id: 361 \t The deal did not * because both parties could not agree. (come off)(topic: 3)\n",
      "doc_id: 478 \t He was * with a fine instead of going to jail. (let off)(topic: 3)\n",
      "doc_id: 439 \t I hope he will * this disappointment soon. (get over)(topic: 3)\n",
      "doc_id: 362 \t I made the effort to tell a few jokes but I don't think they *. (come off)(topic: 3)\n",
      "doc_id: 490 \t She was so persistent that I had to *. (give in)(topic: 3)\n"
     ]
    }
   ],
   "source": [
    "query = select_random_query(1)\n",
    "\n",
    "run_query_default_qa(query)\n",
    "print('')\n",
    "run_query_lambdamart_baseline_model1(query)\n",
    "print('')\n",
    "run_query_lambdamart_model1(query)\n",
    "print('')\n",
    "\n",
    "run_query_default_ss(query)\n",
    "print('')\n",
    "run_query_lambdamart_baseline_model2(query)\n",
    "print('')\n",
    "run_query_lambdamart_model2(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

java -jar RankLib-2.14.jar -train ../data/training/model1_train.txt -test ../data/training/model1_test.txt -validate ../data/training/model1_validate.txt -ranker 6 -metric2t NDCG@10 -metric2T NDCG@10 -save ../model/final/model1.txt

Discard orig. features
Training data:	../data/training/model1_train.txt
Test data:	../data/training/model1_test.txt
Validation data:	../data/training/model1_validate.txt
Feature vector representation: Dense.
Ranking method:	LambdaMART
Feature description file:	Unspecified. All features will be used.
Train metric:	NDCG@10
Test metric:	NDCG@10
Feature normalization: No
Model file: ../model/final/model1.txt

[+] LambdaMART's Parameters:
No. of trees: 1000
No. of leaves: 10
No. of threshold candidates: 256
Min leaf support: 1
Learning rate: 0.1
Stop early: 100 rounds without performance gain on validation data

Reading feature file [../data/training/model1_train.txt]... [Done.]            
(152 ranked lists, 7600 entries read)
Reading feature file [../data/training/model1_validate.txt]... [Done.]            
(75 ranked lists, 3750 entries read)
Reading feature file [../data/training/model1_test.txt]... [Done.]            
(77 ranked lists, 3850 entries read)
Initializing... [Done]
---------------------------------
Training starts...
---------------------------------
#iter   | NDCG@10-T | NDCG@10-V | 
---------------------------------
1       | 0.8604    | 0.8767    | 
2       | 0.9493    | 0.9751    | 
3       | 0.9514    | 0.9788    | 
4       | 0.9509    | 0.9788    | 
5       | 0.9509    | 0.9788    | 
6       | 0.9509    | 0.9788    | 
7       | 0.9509    | 0.9798    | 
8       | 0.9509    | 0.9798    | 
9       | 0.9514    | 0.98      | 
10      | 0.9514    | 0.98      | 
11      | 0.9514    | 0.98      | 
12      | 0.9514    | 0.98      | 
13      | 0.9514    | 0.98      | 
14      | 0.9514    | 0.98      | 
15      | 0.9514    | 0.98      | 
16      | 0.9514    | 0.98      | 
17      | 0.9515    | 0.98      | 
18      | 0.9515    | 0.98      | 
19      | 0.9516    | 0.9849    | 
20      | 0.9516    | 0.9849    | 
21      | 0.9516    | 0.9849    | 
22      | 0.952     | 0.9849    | 
23      | 0.952     | 0.9849    | 
24      | 0.9524    | 0.9857    | 
25      | 0.9524    | 0.9857    | 
26      | 0.9524    | 0.9857    | 
27      | 0.9524    | 0.9857    | 
28      | 0.9524    | 0.9857    | 
29      | 0.9534    | 0.9857    | 
30      | 0.9535    | 0.9857    | 
31      | 0.9535    | 0.9857    | 
32      | 0.9535    | 0.9857    | 
33      | 0.9535    | 0.9857    | 
34      | 0.9535    | 0.9857    | 
35      | 0.9535    | 0.9857    | 
36      | 0.9535    | 0.9857    | 
37      | 0.9535    | 0.9857    | 
38      | 0.9539    | 0.9867    | 
39      | 0.9539    | 0.9867    | 
40      | 0.9539    | 0.9867    | 
41      | 0.9539    | 0.9867    | 
42      | 0.9539    | 0.9867    | 
43      | 0.9539    | 0.9867    | 
44      | 0.9539    | 0.9867    | 
45      | 0.9539    | 0.9867    | 
46      | 0.9539    | 0.9867    | 
47      | 0.9539    | 0.9867    | 
48      | 0.9539    | 0.9867    | 
49      | 0.9539    | 0.9867    | 
50      | 0.9539    | 0.9867    | 
51      | 0.9539    | 0.9867    | 
52      | 0.9539    | 0.9867    | 
53      | 0.9539    | 0.9867    | 
54      | 0.9539    | 0.9867    | 
55      | 0.9539    | 0.9867    | 
56      | 0.9539    | 0.9867    | 
57      | 0.9539    | 0.9867    | 
58      | 0.9539    | 0.9867    | 
59      | 0.9539    | 0.9867    | 
60      | 0.9539    | 0.9867    | 
61      | 0.9539    | 0.9867    | 
62      | 0.9539    | 0.9867    | 
63      | 0.9539    | 0.9867    | 
64      | 0.9539    | 0.9867    | 
65      | 0.9539    | 0.9867    | 
66      | 0.9539    | 0.9867    | 
67      | 0.9539    | 0.9867    | 
68      | 0.9539    | 0.9867    | 
69      | 0.9539    | 0.9867    | 
70      | 0.9539    | 0.9867    | 
71      | 0.9539    | 0.9867    | 
72      | 0.9539    | 0.9867    | 
73      | 0.9539    | 0.9867    | 
74      | 0.9539    | 0.9867    | 
75      | 0.9539    | 0.9867    | 
76      | 0.9539    | 0.9867    | 
77      | 0.9539    | 0.9867    | 
78      | 0.9539    | 0.9867    | 
79      | 0.9539    | 0.9867    | 
80      | 0.9539    | 0.9867    | 
81      | 0.9539    | 0.9867    | 
82      | 0.9539    | 0.9867    | 
83      | 0.9539    | 0.9867    | 
84      | 0.9539    | 0.9867    | 
85      | 0.9539    | 0.9867    | 
86      | 0.9539    | 0.9867    | 
87      | 0.9539    | 0.9867    | 
88      | 0.9539    | 0.9867    | 
89      | 0.9539    | 0.9867    | 
90      | 0.9539    | 0.9867    | 
91      | 0.9539    | 0.9867    | 
92      | 0.9539    | 0.9867    | 
93      | 0.9539    | 0.9867    | 
94      | 0.9539    | 0.9867    | 
95      | 0.9539    | 0.9867    | 
96      | 0.9539    | 0.9867    | 
97      | 0.9539    | 0.9867    | 
98      | 0.9539    | 0.9867    | 
99      | 0.9539    | 0.9867    | 
100     | 0.9539    | 0.9867    | 
101     | 0.9539    | 0.9867    | 
102     | 0.9539    | 0.9867    | 
103     | 0.9539    | 0.9867    | 
104     | 0.9539    | 0.9867    | 
105     | 0.9539    | 0.9867    | 
106     | 0.9539    | 0.9867    | 
107     | 0.9539    | 0.9867    | 
108     | 0.9539    | 0.9867    | 
109     | 0.9539    | 0.9867    | 
110     | 0.9539    | 0.9867    | 
111     | 0.9539    | 0.9867    | 
112     | 0.9539    | 0.9867    | 
113     | 0.9539    | 0.9867    | 
114     | 0.9539    | 0.9867    | 
115     | 0.9539    | 0.9867    | 
116     | 0.9539    | 0.9867    | 
117     | 0.9539    | 0.9867    | 
118     | 0.9539    | 0.9867    | 
119     | 0.9539    | 0.9867    | 
120     | 0.9539    | 0.9867    | 
121     | 0.9539    | 0.9867    | 
122     | 0.9539    | 0.9867    | 
123     | 0.9539    | 0.9867    | 
124     | 0.9539    | 0.9867    | 
125     | 0.9539    | 0.9867    | 
126     | 0.9539    | 0.9867    | 
127     | 0.9539    | 0.9867    | 
128     | 0.9539    | 0.9867    | 
129     | 0.9539    | 0.9867    | 
130     | 0.9539    | 0.9867    | 
131     | 0.9539    | 0.9867    | 
132     | 0.9539    | 0.9867    | 
133     | 0.9539    | 0.9867    | 
134     | 0.9539    | 0.9867    | 
135     | 0.9539    | 0.9867    | 
136     | 0.9539    | 0.9867    | 
137     | 0.9539    | 0.9867    | 
138     | 0.9539    | 0.9867    | 
139     | 0.9539    | 0.9867    | 
---------------------------------
Finished sucessfully.
NDCG@10 on training data: 0.9539
NDCG@10 on validation data: 0.9867
---------------------------------
NDCG@10 on test data: 0.9091

Model saved to: ../model/final/model1.txt
